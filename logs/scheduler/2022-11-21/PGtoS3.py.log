[2022-11-21T19:04:56.026+0000] {processor.py:154} INFO - Started process (PID=12641) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:04:56.028+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:04:56.030+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:04:56.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:04:56.213+0000] {processor.py:766} INFO - DAG(s) dict_keys(['first_dag']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:04:56.274+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:04:56.274+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:04:56.468+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:04:56.468+0000] {dag.py:3340} INFO - Setting next_dagrun for first_dag to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:04:56.493+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.470 seconds
[2022-11-21T19:05:27.216+0000] {processor.py:154} INFO - Started process (PID=12675) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:05:27.220+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:05:27.226+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:05:27.226+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:05:27.412+0000] {processor.py:766} INFO - DAG(s) dict_keys(['first_dag']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:05:27.452+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:05:27.452+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:05:27.470+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:05:27.470+0000] {dag.py:3340} INFO - Setting next_dagrun for first_dag to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:05:27.482+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.272 seconds
[2022-11-21T19:05:38.121+0000] {processor.py:154} INFO - Started process (PID=12687) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:05:38.129+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:05:38.137+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:05:38.136+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:05:38.376+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:05:38.354+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 24
    t1 = PostgresToS3Operator(, database, user, password):)
                              ^
SyntaxError: invalid syntax
[2022-11-21T19:05:38.399+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:05:38.610+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.513 seconds
[2022-11-21T19:06:08.833+0000] {processor.py:154} INFO - Started process (PID=12711) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:06:08.837+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:06:08.839+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:06:08.838+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:06:08.863+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:06:08.861+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 24
    t1 = PostgresToS3Operator(, database, user, password):)
                              ^
SyntaxError: invalid syntax
[2022-11-21T19:06:08.866+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:06:08.903+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.090 seconds
[2022-11-21T19:06:37.295+0000] {processor.py:154} INFO - Started process (PID=12745) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:06:37.298+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:06:37.301+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:06:37.301+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:06:37.317+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:06:37.315+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:06:37.318+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:06:37.356+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.071 seconds
[2022-11-21T19:07:07.654+0000] {processor.py:154} INFO - Started process (PID=12777) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:07:07.656+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:07:07.658+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:07:07.657+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:07:07.665+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:07:07.664+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:07:07.666+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:07:07.688+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.036 seconds
[2022-11-21T19:07:38.222+0000] {processor.py:154} INFO - Started process (PID=12801) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:07:38.226+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:07:38.229+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:07:38.229+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:07:38.243+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:07:38.240+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:07:38.246+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:07:38.270+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.053 seconds
[2022-11-21T19:08:08.778+0000] {processor.py:154} INFO - Started process (PID=12834) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:08:08.782+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:08:08.784+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:08:08.783+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:08:08.795+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:08:08.794+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:08:08.797+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:08:08.822+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.049 seconds
[2022-11-21T19:08:39.493+0000] {processor.py:154} INFO - Started process (PID=12866) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:08:39.498+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:08:39.501+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:08:39.500+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:08:39.514+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:08:39.513+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:08:39.516+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:08:39.541+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.054 seconds
[2022-11-21T19:09:10.044+0000] {processor.py:154} INFO - Started process (PID=12899) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:09:10.048+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:09:10.050+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:09:10.050+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:09:10.062+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:09:10.061+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:09:10.064+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:09:10.087+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.048 seconds
[2022-11-21T19:09:40.441+0000] {processor.py:154} INFO - Started process (PID=12923) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:09:40.444+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:09:40.446+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:09:40.446+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:09:40.460+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:09:40.459+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:09:40.462+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:09:40.484+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.049 seconds
[2022-11-21T19:10:10.628+0000] {processor.py:154} INFO - Started process (PID=12955) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:10.632+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:10:10.635+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:10:10.635+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:10.662+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:10:10.661+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25
    database, user, password):)
                             ^
SyntaxError: invalid syntax
[2022-11-21T19:10:10.663+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:10.687+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.066 seconds
[2022-11-21T19:10:29.205+0000] {processor.py:154} INFO - Started process (PID=12979) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:29.213+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:10:29.215+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:10:29.215+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:29.235+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:10:29.233+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11
    from
        ^
SyntaxError: invalid syntax
[2022-11-21T19:10:29.249+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:29.292+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.102 seconds
[2022-11-21T19:10:59.864+0000] {processor.py:154} INFO - Started process (PID=13013) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:59.874+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:10:59.880+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:10:59.880+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:59.911+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:10:59.909+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11
    from
        ^
SyntaxError: invalid syntax
[2022-11-21T19:10:59.914+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:10:59.952+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.094 seconds
[2022-11-21T19:11:30.619+0000] {processor.py:154} INFO - Started process (PID=13037) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:11:30.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:11:30.627+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:11:30.627+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:11:30.661+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:11:30.659+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11
    from
        ^
SyntaxError: invalid syntax
[2022-11-21T19:11:30.664+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:11:30.689+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.074 seconds
[2022-11-21T19:11:46.949+0000] {processor.py:154} INFO - Started process (PID=13057) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:11:46.953+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:11:46.955+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:11:46.955+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:11:47.557+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:11:47.546+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.models.baseoperator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'airflow.models.baseoperator' (/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py)
[2022-11-21T19:11:47.561+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:11:47.618+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.681 seconds
[2022-11-21T19:12:18.129+0000] {processor.py:154} INFO - Started process (PID=13090) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:12:18.132+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:12:18.134+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:12:18.134+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:12:18.353+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:12:18.349+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.models.baseoperator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'airflow.models.baseoperator' (/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py)
[2022-11-21T19:12:18.357+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:12:18.395+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.270 seconds
[2022-11-21T19:12:48.903+0000] {processor.py:154} INFO - Started process (PID=13116) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:12:48.906+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:12:48.908+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:12:48.908+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:12:49.103+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:12:49.098+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.models.baseoperator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'airflow.models.baseoperator' (/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py)
[2022-11-21T19:12:49.106+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:12:49.136+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.238 seconds
[2022-11-21T19:13:19.654+0000] {processor.py:154} INFO - Started process (PID=13150) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:13:19.662+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:13:19.665+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:13:19.665+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:13:19.919+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:13:19.915+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.models.baseoperator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'airflow.models.baseoperator' (/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py)
[2022-11-21T19:13:19.921+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:13:19.945+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.300 seconds
[2022-11-21T19:13:33.921+0000] {processor.py:154} INFO - Started process (PID=13165) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:13:33.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:13:33.926+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:13:33.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:13:34.242+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:13:34.235+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:13:34.244+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:13:34.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.384 seconds
[2022-11-21T19:14:04.400+0000] {processor.py:154} INFO - Started process (PID=13200) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:14:04.404+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:14:04.407+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:14:04.407+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:14:04.646+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:14:04.640+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:14:04.648+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:14:04.674+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.294 seconds
[2022-11-21T19:14:35.456+0000] {processor.py:154} INFO - Started process (PID=13233) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:14:35.460+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:14:35.462+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:14:35.462+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:14:35.632+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:14:35.627+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:14:35.634+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:14:35.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.202 seconds
[2022-11-21T19:15:06.348+0000] {processor.py:154} INFO - Started process (PID=13266) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:15:06.351+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:15:06.353+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:15:06.353+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:15:06.510+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:15:06.507+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:15:06.512+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:15:06.532+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.187 seconds
[2022-11-21T19:15:36.981+0000] {processor.py:154} INFO - Started process (PID=13291) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:15:36.985+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:15:36.987+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:15:36.987+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:15:37.146+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:15:37.143+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:15:37.148+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:15:37.167+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.192 seconds
[2022-11-21T19:16:03.600+0000] {processor.py:154} INFO - Started process (PID=13325) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:16:03.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:16:03.611+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:16:03.611+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:16:04.237+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:16:04.232+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
  File "/opt/airflow/plugins/FromPostgressToS3Operator.py", line 3, in <module>
    from airflow.hooks.postgress_hooks import PostgressHook
ModuleNotFoundError: No module named 'airflow.hooks.postgress_hooks'
[2022-11-21T19:16:04.240+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:16:04.264+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.668 seconds
[2022-11-21T19:16:34.599+0000] {processor.py:154} INFO - Started process (PID=13358) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:16:34.601+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:16:34.606+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:16:34.605+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:16:34.939+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:16:34.934+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
  File "/opt/airflow/plugins/FromPostgressToS3Operator.py", line 3, in <module>
    from airflow.hooks.postgress_hooks import PostgressHook
ModuleNotFoundError: No module named 'airflow.hooks.postgress_hooks'
[2022-11-21T19:16:34.942+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:16:34.958+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.361 seconds
[2022-11-21T19:17:05.559+0000] {processor.py:154} INFO - Started process (PID=13383) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:05.562+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:17:05.564+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:17:05.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:05.949+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:17:05.944+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 11, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
  File "/opt/airflow/plugins/FromPostgressToS3Operator.py", line 3, in <module>
    from airflow.hooks.postgress_hooks import PostgressHook
ModuleNotFoundError: No module named 'airflow.hooks.postgress_hooks'
[2022-11-21T19:17:05.952+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:05.975+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.420 seconds
[2022-11-21T19:17:16.240+0000] {processor.py:154} INFO - Started process (PID=13395) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:16.246+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:17:16.248+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:17:16.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:16.432+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:17:16.422+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
  File "/opt/airflow/plugins/FromPostgressToS3Operator.py", line 3, in <module>
    from airflow.hooks.postgress_hooks import PostgressHook
ModuleNotFoundError: No module named 'airflow.hooks.postgress_hooks'
[2022-11-21T19:17:16.437+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:16.478+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.264 seconds
[2022-11-21T19:17:46.923+0000] {processor.py:154} INFO - Started process (PID=13428) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:46.927+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:17:46.929+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:17:46.929+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:47.015+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:17:47.010+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
  File "/opt/airflow/plugins/FromPostgressToS3Operator.py", line 3, in <module>
    from airflow.hooks.postgress_hooks import PostgressHook
ModuleNotFoundError: No module named 'airflow.hooks.postgress_hooks'
[2022-11-21T19:17:47.028+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:17:47.048+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.129 seconds
[2022-11-21T19:18:17.627+0000] {processor.py:154} INFO - Started process (PID=13460) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:18:17.629+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:18:17.630+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:18:17.630+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:18:17.664+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:18:17.661+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'FromPostgressToS3Operator' (/opt/airflow/plugins/FromPostgressToS3Operator.py)
[2022-11-21T19:18:17.666+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:18:17.690+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.068 seconds
[2022-11-21T19:18:48.275+0000] {processor.py:154} INFO - Started process (PID=13492) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:18:48.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:18:48.281+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:18:48.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:18:48.304+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:18:48.298+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'FromPostgressToS3Operator' (/opt/airflow/plugins/FromPostgressToS3Operator.py)
[2022-11-21T19:18:48.306+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:18:48.328+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.056 seconds
[2022-11-21T19:19:18.942+0000] {processor.py:154} INFO - Started process (PID=13516) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:19:18.946+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:19:18.948+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:19:18.948+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:19:18.969+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:19:18.966+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'FromPostgressToS3Operator' (/opt/airflow/plugins/FromPostgressToS3Operator.py)
[2022-11-21T19:19:18.971+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:19:18.990+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.054 seconds
[2022-11-21T19:19:49.530+0000] {processor.py:154} INFO - Started process (PID=13549) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:19:49.533+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:19:49.535+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:19:49.535+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:19:49.550+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:19:49.548+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'FromPostgressToS3Operator' (/opt/airflow/plugins/FromPostgressToS3Operator.py)
[2022-11-21T19:19:49.552+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:19:49.571+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.046 seconds
[2022-11-21T19:20:20.167+0000] {processor.py:154} INFO - Started process (PID=13582) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:20:20.172+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:20:20.174+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:20:20.174+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:20:20.194+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:20:20.191+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from FromPostgressToS3Operator import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'FromPostgressToS3Operator' (/opt/airflow/plugins/FromPostgressToS3Operator.py)
[2022-11-21T19:20:20.195+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:20:20.216+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.054 seconds
[2022-11-21T19:20:33.581+0000] {processor.py:154} INFO - Started process (PID=13593) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:20:33.586+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:20:33.590+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:20:33.590+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:20:33.669+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:20:33.663+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:20:33.679+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:20:33.730+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.158 seconds
[2022-11-21T19:21:04.028+0000] {processor.py:154} INFO - Started process (PID=13626) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:21:04.031+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:21:04.033+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:21:04.032+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:21:04.050+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:21:04.048+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:21:04.053+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:21:04.071+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.046 seconds
[2022-11-21T19:21:35.099+0000] {processor.py:154} INFO - Started process (PID=13659) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:21:35.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:21:35.103+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:21:35.103+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:21:35.119+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:21:35.115+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:21:35.121+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:21:35.139+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.044 seconds
[2022-11-21T19:22:05.785+0000] {processor.py:154} INFO - Started process (PID=13681) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:22:05.795+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:22:05.804+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:22:05.804+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:22:05.843+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:22:05.839+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:22:05.847+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:22:05.872+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.095 seconds
[2022-11-21T19:22:36.448+0000] {processor.py:154} INFO - Started process (PID=13714) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:22:36.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:22:36.456+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:22:36.456+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:22:36.472+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:22:36.469+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:22:36.480+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:22:36.499+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.054 seconds
[2022-11-21T19:23:06.821+0000] {processor.py:154} INFO - Started process (PID=13747) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:23:06.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:23:06.826+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:23:06.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:23:06.848+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:23:06.845+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:23:06.850+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:23:06.888+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.072 seconds
[2022-11-21T19:23:37.064+0000] {processor.py:154} INFO - Started process (PID=13780) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:23:37.066+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:23:37.068+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:23:37.068+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:23:37.082+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:23:37.077+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:23:37.083+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:23:37.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.041 seconds
[2022-11-21T19:24:07.711+0000] {processor.py:154} INFO - Started process (PID=13803) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:07.713+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:24:07.715+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:24:07.715+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:07.727+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:24:07.725+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'plugins'
[2022-11-21T19:24:07.729+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:07.749+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.041 seconds
[2022-11-21T19:24:19.048+0000] {processor.py:154} INFO - Started process (PID=13815) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:19.061+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:24:19.071+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:24:19.070+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:19.181+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:24:19.166+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:24:19.191+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:19.275+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.249 seconds
[2022-11-21T19:24:49.693+0000] {processor.py:154} INFO - Started process (PID=13849) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:49.699+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:24:49.703+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:24:49.703+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:49.728+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:24:49.723+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:24:49.729+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:24:49.755+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.069 seconds
[2022-11-21T19:25:20.142+0000] {processor.py:154} INFO - Started process (PID=13880) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:25:20.145+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:25:20.147+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:25:20.147+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:25:20.162+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:25:20.160+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:25:20.164+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:25:20.184+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.046 seconds
[2022-11-21T19:25:50.225+0000] {processor.py:154} INFO - Started process (PID=13914) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:25:50.227+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:25:50.230+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:25:50.230+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:25:50.252+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:25:50.250+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:25:50.255+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:25:50.275+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.053 seconds
[2022-11-21T19:26:20.349+0000] {processor.py:154} INFO - Started process (PID=13937) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:26:20.352+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:26:20.354+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:26:20.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:26:20.369+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:26:20.366+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:26:20.371+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:26:20.393+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.048 seconds
[2022-11-21T19:26:50.964+0000] {processor.py:154} INFO - Started process (PID=13969) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:26:50.967+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:26:50.968+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:26:50.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:26:50.982+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:26:50.980+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:26:50.984+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:26:51.004+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.045 seconds
[2022-11-21T19:27:21.186+0000] {processor.py:154} INFO - Started process (PID=14002) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:27:21.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:27:21.190+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:27:21.190+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:27:21.203+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:27:21.200+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:27:21.204+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:27:21.226+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.042 seconds
[2022-11-21T19:27:48.746+0000] {processor.py:154} INFO - Started process (PID=14024) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:27:48.749+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:27:48.752+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:27:48.751+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:27:48.783+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:27:48.780+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:27:48.785+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:27:48.812+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.074 seconds
[2022-11-21T19:28:19.403+0000] {processor.py:154} INFO - Started process (PID=14056) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:28:19.407+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:28:19.410+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:28:19.410+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:28:19.433+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:28:19.430+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:28:19.435+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:28:19.456+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.057 seconds
[2022-11-21T19:28:49.588+0000] {processor.py:154} INFO - Started process (PID=14089) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:28:49.593+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:28:49.596+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:28:49.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:28:49.614+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:28:49.612+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from airflow.plugins import FromPostgressToS3Operator
ModuleNotFoundError: No module named 'airflow.plugins'
[2022-11-21T19:28:49.617+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:28:49.639+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.055 seconds
[2022-11-21T19:29:00.878+0000] {processor.py:154} INFO - Started process (PID=14102) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:00.881+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:29:00.884+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:29:00.883+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:01.080+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:29:01.076+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'operators.pgtos3' (/opt/airflow/plugins/operators/pgtos3.py)
[2022-11-21T19:29:01.083+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:01.148+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.281 seconds
[2022-11-21T19:29:31.225+0000] {processor.py:154} INFO - Started process (PID=14126) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:31.229+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:29:31.231+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:29:31.230+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:31.271+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:29:31.268+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import FromPostgressToS3Operator
ImportError: cannot import name 'FromPostgressToS3Operator' from 'operators.pgtos3' (/opt/airflow/plugins/operators/pgtos3.py)
[2022-11-21T19:29:31.273+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:31.304+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.087 seconds
[2022-11-21T19:29:49.668+0000] {processor.py:154} INFO - Started process (PID=14147) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:49.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:29:49.672+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:29:49.672+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:49.719+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:29:49.717+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    postgres,
NameError: name 'postgres' is not defined
[2022-11-21T19:29:49.722+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:29:49.756+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.091 seconds
[2022-11-21T19:30:20.319+0000] {processor.py:154} INFO - Started process (PID=14180) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:30:20.322+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:30:20.324+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:30:20.324+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:30:20.353+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:30:20.350+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    postgres,
NameError: name 'postgres' is not defined
[2022-11-21T19:30:20.355+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:30:20.377+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.062 seconds
[2022-11-21T19:30:36.766+0000] {processor.py:154} INFO - Started process (PID=14194) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:30:36.772+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:30:36.776+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:30:36.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:30:36.895+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:30:36.890+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:30:36.896+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:30:36.918+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.158 seconds
[2022-11-21T19:31:07.841+0000] {processor.py:154} INFO - Started process (PID=14227) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:31:07.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:31:07.847+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:31:07.847+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:31:07.883+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:31:07.880+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:31:07.896+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:31:07.920+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.084 seconds
[2022-11-21T19:31:38.455+0000] {processor.py:154} INFO - Started process (PID=14259) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:31:38.458+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:31:38.460+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:31:38.460+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:31:38.520+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:31:38.518+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:31:38.523+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:31:38.546+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.097 seconds
[2022-11-21T19:32:08.633+0000] {processor.py:154} INFO - Started process (PID=14293) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:32:08.637+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:32:08.640+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:32:08.640+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:32:08.758+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:32:08.751+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:32:08.768+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:32:08.813+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.184 seconds
[2022-11-21T19:32:39.262+0000] {processor.py:154} INFO - Started process (PID=14317) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:32:39.265+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:32:39.269+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:32:39.269+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:32:39.299+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:32:39.296+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:32:39.300+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:32:39.319+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.062 seconds
[2022-11-21T19:33:10.046+0000] {processor.py:154} INFO - Started process (PID=14349) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:33:10.049+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:33:10.051+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:33:10.051+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:33:10.096+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:33:10.092+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:33:10.098+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:33:10.126+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.084 seconds
[2022-11-21T19:33:40.819+0000] {processor.py:154} INFO - Started process (PID=14383) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:33:40.822+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:33:40.828+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:33:40.828+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:33:40.855+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:33:40.852+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:33:40.856+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:33:40.881+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.067 seconds
[2022-11-21T19:34:10.958+0000] {processor.py:154} INFO - Started process (PID=14414) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:34:10.962+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:34:10.965+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:34:10.965+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:34:11.045+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:34:11.030+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:34:11.049+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:34:11.080+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.126 seconds
[2022-11-21T19:34:41.219+0000] {processor.py:154} INFO - Started process (PID=14440) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:34:41.222+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:34:41.224+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:34:41.224+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:34:41.273+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:34:41.270+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:34:41.275+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:34:41.300+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.086 seconds
[2022-11-21T19:35:11.762+0000] {processor.py:154} INFO - Started process (PID=14472) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:35:11.767+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:35:11.770+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:35:11.769+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:35:11.833+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:35:11.830+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:35:11.835+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:35:11.861+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.109 seconds
[2022-11-21T19:35:42.542+0000] {processor.py:154} INFO - Started process (PID=14506) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:35:42.548+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:35:42.550+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:35:42.550+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:35:42.599+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:35:42.596+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:35:42.600+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:35:42.619+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.082 seconds
[2022-11-21T19:36:13.255+0000] {processor.py:154} INFO - Started process (PID=14539) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:36:13.266+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:36:13.271+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:36:13.271+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:36:13.325+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:36:13.323+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:36:13.327+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:36:13.346+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.095 seconds
[2022-11-21T19:36:43.940+0000] {processor.py:154} INFO - Started process (PID=14562) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:36:43.948+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:36:43.952+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:36:43.951+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:36:44.040+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:36:44.034+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:36:44.050+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:36:44.089+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.162 seconds
[2022-11-21T19:37:14.614+0000] {processor.py:154} INFO - Started process (PID=14597) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:37:14.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:37:14.619+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:37:14.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:37:14.677+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:37:14.664+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:37:14.679+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:37:14.703+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.094 seconds
[2022-11-21T19:37:44.798+0000] {processor.py:154} INFO - Started process (PID=14630) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:37:44.802+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:37:44.804+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:37:44.804+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:37:44.836+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:37:44.833+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:37:44.840+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:37:44.872+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.078 seconds
[2022-11-21T19:38:15.565+0000] {processor.py:154} INFO - Started process (PID=14662) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:38:15.573+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:38:15.594+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:38:15.594+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:38:15.649+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:38:15.644+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:38:15.652+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:38:15.678+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.119 seconds
[2022-11-21T19:38:46.208+0000] {processor.py:154} INFO - Started process (PID=14686) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:38:46.210+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:38:46.216+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:38:46.216+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:38:46.262+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:38:46.259+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:38:46.265+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:38:46.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.080 seconds
[2022-11-21T19:39:16.902+0000] {processor.py:154} INFO - Started process (PID=14719) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:39:16.905+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:39:16.906+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:39:16.906+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:39:16.965+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:39:16.950+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
ImportError: cannot import name 'PostgresToS3Operator' from 'operators.pgtos3' (/opt/airflow/plugins/operators/pgtos3.py)
[2022-11-21T19:39:16.968+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:39:16.999+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.100 seconds
[2022-11-21T19:39:47.072+0000] {processor.py:154} INFO - Started process (PID=14752) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:39:47.075+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:39:47.077+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:39:47.076+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:39:47.110+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:39:47.106+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
ImportError: cannot import name 'PostgresToS3Operator' from 'operators.pgtos3' (/opt/airflow/plugins/operators/pgtos3.py)
[2022-11-21T19:39:47.112+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:39:47.134+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.065 seconds
[2022-11-21T19:40:17.234+0000] {processor.py:154} INFO - Started process (PID=14775) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:40:17.237+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:40:17.241+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:40:17.241+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:40:17.380+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:40:17.376+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:40:17.381+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:40:17.409+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.180 seconds
[2022-11-21T19:40:48.243+0000] {processor.py:154} INFO - Started process (PID=14808) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:40:48.247+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:40:48.253+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:40:48.253+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:40:48.291+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:40:48.287+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:40:48.294+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:40:48.312+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.076 seconds
[2022-11-21T19:41:18.953+0000] {processor.py:154} INFO - Started process (PID=14840) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:18.957+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:41:18.959+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:41:18.959+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:18.989+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:41:18.986+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:41:19.001+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:19.022+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.075 seconds
[2022-11-21T19:41:49.655+0000] {processor.py:154} INFO - Started process (PID=14872) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:49.658+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:41:49.659+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:41:49.659+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:49.688+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:41:49.682+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 22, in <module>
    "postgres")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:41:49.691+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:49.713+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.062 seconds
[2022-11-21T19:41:53.742+0000] {processor.py:154} INFO - Started process (PID=14873) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:53.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:41:53.747+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:41:53.747+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:53.881+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:41:53.876+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 19, in <module>
    t1 = PostgresToS3Operator("database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:41:53.887+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:41:53.929+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.191 seconds
[2022-11-21T19:42:24.493+0000] {processor.py:154} INFO - Started process (PID=14906) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:42:24.496+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:42:24.497+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:42:24.497+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:42:24.568+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:42:24.564+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 19, in <module>
    t1 = PostgresToS3Operator("database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:42:24.572+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:42:24.607+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.118 seconds
[2022-11-21T19:42:55.098+0000] {processor.py:154} INFO - Started process (PID=14938) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:42:55.100+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:42:55.103+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:42:55.103+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:42:55.154+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:42:55.151+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 19, in <module>
    t1 = PostgresToS3Operator("database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 366, in apply_defaults
    raise AirflowException("Use keyword arguments when initializing operators")
airflow.exceptions.AirflowException: Use keyword arguments when initializing operators
[2022-11-21T19:42:55.155+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:42:55.177+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.085 seconds
[2022-11-21T19:43:10.462+0000] {processor.py:154} INFO - Started process (PID=14951) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:43:10.473+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:43:10.482+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:43:10.481+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:43:10.606+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:43:10.598+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 19, in <module>
    t1 = PostgresToS3Operator(name="database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T19:43:10.608+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:43:10.637+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.180 seconds
[2022-11-21T19:43:41.108+0000] {processor.py:154} INFO - Started process (PID=14983) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:43:41.113+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:43:41.115+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:43:41.115+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:43:41.154+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:43:41.146+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 19, in <module>
    t1 = PostgresToS3Operator(name="database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T19:43:41.156+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:43:41.178+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.074 seconds
[2022-11-21T19:44:11.757+0000] {processor.py:154} INFO - Started process (PID=15017) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:44:11.761+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:44:11.763+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:44:11.763+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:44:11.797+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:44:11.792+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 19, in <module>
    t1 = PostgresToS3Operator(name="database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T19:44:11.799+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:44:11.818+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.065 seconds
[2022-11-21T19:44:42.421+0000] {processor.py:154} INFO - Started process (PID=15040) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:44:42.423+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:44:42.425+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:44:42.425+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:44:42.457+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:44:42.453+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 19, in <module>
    t1 = PostgresToS3Operator(name="database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T19:44:42.458+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:44:42.481+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.064 seconds
[2022-11-21T19:45:02.059+0000] {processor.py:154} INFO - Started process (PID=15062) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:02.062+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:45:02.064+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:45:02.063+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:02.088+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:45:02.087+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    name="database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
        ^
SyntaxError: invalid syntax
[2022-11-21T19:45:02.105+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:02.150+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.097 seconds
[2022-11-21T19:45:32.206+0000] {processor.py:154} INFO - Started process (PID=15095) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:32.208+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:45:32.210+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:45:32.209+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:32.220+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:45:32.218+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    name="database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
        ^
SyntaxError: invalid syntax
[2022-11-21T19:45:32.222+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:32.248+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.047 seconds
[2022-11-21T19:45:57.008+0000] {processor.py:154} INFO - Started process (PID=15116) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:57.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:45:57.017+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:45:57.017+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:57.140+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:45:57.132+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20, in <module>
    name="database-1.c5wlg9mvdxqs.us-east-1.rds.amazonaws.com")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 391, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'host'
[2022-11-21T19:45:57.142+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:45:57.180+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.178 seconds
[2022-11-21T19:46:12.608+0000] {processor.py:154} INFO - Started process (PID=15137) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:46:12.611+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:46:12.620+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:12.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:46:12.843+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:46:13.014+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:13.014+0000] {manager.py:507} INFO - Created Permission View: can delete on DAG:PG_to_S3
[2022-11-21T19:46:13.037+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:13.037+0000] {manager.py:507} INFO - Created Permission View: can read on DAG:PG_to_S3
[2022-11-21T19:46:13.058+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:13.058+0000] {manager.py:507} INFO - Created Permission View: can edit on DAG:PG_to_S3
[2022-11-21T19:46:13.061+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:13.060+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:46:13.075+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:13.075+0000] {dag.py:2606} INFO - Creating ORM DAG for PG_to_S3
[2022-11-21T19:46:13.089+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:13.089+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-20T00:00:00+00:00, run_after=2022-11-21T00:00:00+00:00
[2022-11-21T19:46:13.120+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.517 seconds
[2022-11-21T19:46:44.013+0000] {processor.py:154} INFO - Started process (PID=15162) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:46:44.017+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:46:44.019+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:44.019+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:46:44.062+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:46:44.100+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:44.100+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:46:44.119+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:46:44.119+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:46:44.132+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.125 seconds
[2022-11-21T19:47:14.727+0000] {processor.py:154} INFO - Started process (PID=15195) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:47:14.731+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:47:14.733+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:47:14.733+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:47:14.762+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:47:14.789+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:47:14.789+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:47:14.806+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:47:14.806+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:47:14.817+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.094 seconds
[2022-11-21T19:47:45.349+0000] {processor.py:154} INFO - Started process (PID=15228) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:47:45.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:47:45.355+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:47:45.355+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:47:45.386+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:47:45.418+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:47:45.418+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:47:45.439+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:47:45.439+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:47:45.452+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.107 seconds
[2022-11-21T19:48:16.138+0000] {processor.py:154} INFO - Started process (PID=15261) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:48:16.142+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:48:16.146+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:48:16.146+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:48:16.204+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:48:16.250+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:48:16.250+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:48:16.277+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:48:16.277+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:48:16.296+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.166 seconds
[2022-11-21T19:48:46.824+0000] {processor.py:154} INFO - Started process (PID=15284) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:48:46.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:48:46.842+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:48:46.842+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:48:46.979+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:48:47.052+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:48:47.052+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:48:47.103+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:48:47.102+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:48:47.121+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.300 seconds
[2022-11-21T19:49:17.251+0000] {processor.py:154} INFO - Started process (PID=15316) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:49:17.254+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:49:17.255+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:49:17.255+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:49:17.289+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:49:17.320+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:49:17.320+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:49:17.336+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:49:17.336+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:49:17.348+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.101 seconds
[2022-11-21T19:49:47.475+0000] {processor.py:154} INFO - Started process (PID=15349) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:49:47.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:49:47.491+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:49:47.491+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:49:47.560+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:49:47.598+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:49:47.598+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:49:47.619+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:49:47.619+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:49:47.634+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.164 seconds
[2022-11-21T19:50:18.211+0000] {processor.py:154} INFO - Started process (PID=15382) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:50:18.217+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:50:18.221+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:50:18.221+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:50:18.320+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:50:18.395+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:50:18.395+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:50:18.438+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:50:18.438+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:50:18.457+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.252 seconds
[2022-11-21T19:50:48.857+0000] {processor.py:154} INFO - Started process (PID=15406) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:50:48.860+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:50:48.861+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:50:48.861+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:50:48.897+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:50:48.927+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:50:48.927+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:50:48.944+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:50:48.944+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:50:48.956+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.101 seconds
[2022-11-21T19:51:19.676+0000] {processor.py:154} INFO - Started process (PID=15438) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:51:19.680+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:51:19.685+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:51:19.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:51:19.754+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:51:19.799+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:51:19.799+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:51:19.823+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:51:19.822+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:51:19.843+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.171 seconds
[2022-11-21T19:51:50.866+0000] {processor.py:154} INFO - Started process (PID=15471) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:51:50.869+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:51:50.871+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:51:50.871+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:51:50.915+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:51:50.958+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:51:50.958+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:51:50.979+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:51:50.979+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:51:50.994+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.133 seconds
[2022-11-21T19:52:21.095+0000] {processor.py:154} INFO - Started process (PID=15496) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:52:21.099+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:52:21.101+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:52:21.101+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:52:21.141+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:52:21.185+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:52:21.185+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:52:21.214+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:52:21.214+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:52:21.232+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.141 seconds
[2022-11-21T19:52:51.419+0000] {processor.py:154} INFO - Started process (PID=15530) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:52:51.424+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:52:51.426+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:52:51.426+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:52:51.471+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:52:51.517+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:52:51.517+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:52:51.551+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:52:51.551+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:52:51.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.165 seconds
[2022-11-21T19:53:06.913+0000] {processor.py:154} INFO - Started process (PID=15551) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:53:06.921+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:53:06.931+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:53:06.930+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:53:07.157+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:53:07.317+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:53:07.317+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:53:07.369+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:53:07.369+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:53:07.454+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.569 seconds
[2022-11-21T19:53:38.515+0000] {processor.py:154} INFO - Started process (PID=15575) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:53:38.519+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:53:38.523+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:53:38.523+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:53:38.561+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:53:38.598+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:53:38.598+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:53:38.617+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:53:38.616+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:53:38.628+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.120 seconds
[2022-11-21T19:54:09.202+0000] {processor.py:154} INFO - Started process (PID=15608) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:54:09.205+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:54:09.206+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:54:09.206+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:54:09.294+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:54:09.349+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:54:09.349+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:54:09.375+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:54:09.375+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:54:09.394+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.197 seconds
[2022-11-21T19:54:39.675+0000] {processor.py:154} INFO - Started process (PID=15641) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:54:39.678+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:54:39.681+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:54:39.681+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:54:39.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:54:39.784+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:54:39.784+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:54:39.804+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:54:39.804+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:54:39.828+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.157 seconds
[2022-11-21T19:55:10.647+0000] {processor.py:154} INFO - Started process (PID=15675) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:55:10.653+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:55:10.656+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:55:10.655+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:55:10.738+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:55:10.776+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:55:10.776+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:55:10.796+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:55:10.796+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:55:10.809+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.167 seconds
[2022-11-21T19:55:40.936+0000] {processor.py:154} INFO - Started process (PID=15699) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:55:40.938+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:55:40.940+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:55:40.940+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:55:40.968+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:55:41.000+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:55:41.000+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:55:41.015+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:55:41.015+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:55:41.026+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.093 seconds
[2022-11-21T19:56:11.902+0000] {processor.py:154} INFO - Started process (PID=15732) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:56:11.906+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:56:11.914+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:56:11.913+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:56:11.944+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:56:11.978+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:56:11.978+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:56:11.998+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:56:11.998+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:56:12.016+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.118 seconds
[2022-11-21T19:56:42.512+0000] {processor.py:154} INFO - Started process (PID=15765) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:56:42.515+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:56:42.517+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:56:42.516+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:56:42.557+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:56:42.593+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:56:42.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:56:42.613+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:56:42.613+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:56:42.625+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.119 seconds
[2022-11-21T19:57:13.183+0000] {processor.py:154} INFO - Started process (PID=15798) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:57:13.199+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:57:13.201+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:57:13.201+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:57:13.233+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:57:13.268+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:57:13.268+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:57:13.287+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:57:13.287+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:57:13.302+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.125 seconds
[2022-11-21T19:57:43.804+0000] {processor.py:154} INFO - Started process (PID=15829) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:57:43.813+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:57:43.820+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:57:43.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:57:43.889+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:57:43.930+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:57:43.929+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:57:43.957+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:57:43.957+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:57:43.981+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.182 seconds
[2022-11-21T19:58:14.685+0000] {processor.py:154} INFO - Started process (PID=15855) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:58:14.689+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:58:14.692+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:58:14.692+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:58:14.743+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:58:14.785+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:58:14.785+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:58:14.808+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:58:14.808+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:58:14.824+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.146 seconds
[2022-11-21T19:58:44.995+0000] {processor.py:154} INFO - Started process (PID=15887) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:58:44.999+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:58:45.000+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:58:45.000+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:58:45.035+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:58:45.073+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:58:45.073+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:58:45.094+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:58:45.094+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:58:45.111+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.120 seconds
[2022-11-21T19:59:15.680+0000] {processor.py:154} INFO - Started process (PID=15920) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:59:15.696+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:59:15.698+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:59:15.698+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:59:15.734+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:59:15.767+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:59:15.767+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:59:15.787+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:59:15.787+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:59:15.800+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.124 seconds
[2022-11-21T19:59:46.376+0000] {processor.py:154} INFO - Started process (PID=15952) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:59:46.382+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T19:59:46.387+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:59:46.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:59:46.443+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T19:59:46.508+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:59:46.508+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T19:59:46.547+0000] {logging_mixin.py:120} INFO - [2022-11-21T19:59:46.547+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T19:59:46.583+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.212 seconds
[2022-11-21T20:00:17.344+0000] {processor.py:154} INFO - Started process (PID=15976) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:00:17.350+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:00:17.352+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:00:17.352+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:00:17.384+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:00:17.419+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:00:17.419+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T20:00:17.440+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:00:17.440+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T20:00:17.456+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.117 seconds
[2022-11-21T20:00:47.969+0000] {processor.py:154} INFO - Started process (PID=16008) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:00:47.972+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:00:47.974+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:00:47.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:00:48.004+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:00:48.041+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:00:48.041+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T20:00:48.060+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:00:48.060+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T20:00:48.075+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.110 seconds
[2022-11-21T20:01:18.621+0000] {processor.py:154} INFO - Started process (PID=16041) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:01:18.625+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:01:18.627+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:01:18.627+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:01:18.679+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:01:18.726+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:01:18.725+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T20:01:18.750+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:01:18.750+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T20:01:18.765+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.152 seconds
[2022-11-21T20:01:49.100+0000] {processor.py:154} INFO - Started process (PID=16073) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:01:49.105+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:01:49.109+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:01:49.109+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:01:49.152+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:01:49.211+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:01:49.211+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T20:01:49.240+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:01:49.240+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T20:01:49.256+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.161 seconds
[2022-11-21T20:02:19.382+0000] {processor.py:154} INFO - Started process (PID=16097) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:02:19.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:02:19.389+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:02:19.389+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:02:19.429+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:02:19.471+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:02:19.471+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T20:02:19.494+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:02:19.494+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T20:02:19.512+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.137 seconds
[2022-11-21T20:02:50.145+0000] {processor.py:154} INFO - Started process (PID=16130) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:02:50.153+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:02:50.155+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:02:50.155+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:02:50.190+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:02:50.234+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:02:50.234+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T20:02:50.259+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:02:50.259+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T20:02:50.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.140 seconds
[2022-11-21T20:03:20.352+0000] {processor.py:154} INFO - Started process (PID=16163) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:03:20.356+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:03:20.358+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:03:20.358+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:03:20.391+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:03:20.427+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:03:20.427+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T20:03:20.449+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:03:20.449+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T20:03:20.461+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.116 seconds
[2022-11-21T20:03:51.010+0000] {processor.py:154} INFO - Started process (PID=16197) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:03:51.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:03:51.016+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:03:51.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:03:51.089+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:03:51.085+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:03:51.092+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:03:51.123+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.117 seconds
[2022-11-21T20:04:21.675+0000] {processor.py:154} INFO - Started process (PID=16221) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:04:21.682+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:04:21.686+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:04:21.686+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:04:21.768+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:04:21.762+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:04:21.775+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:04:21.804+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.133 seconds
[2022-11-21T20:04:52.370+0000] {processor.py:154} INFO - Started process (PID=16254) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:04:52.386+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:04:52.390+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:04:52.390+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:04:52.427+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:04:52.423+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:04:52.428+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:04:52.453+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.092 seconds
[2022-11-21T20:05:23.076+0000] {processor.py:154} INFO - Started process (PID=16287) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:05:23.079+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:05:23.081+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:05:23.081+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:05:23.122+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:05:23.118+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:05:23.124+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:05:23.151+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.082 seconds
[2022-11-21T20:05:53.216+0000] {processor.py:154} INFO - Started process (PID=16319) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:05:53.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:05:53.219+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:05:53.219+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:05:53.247+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:05:53.244+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:05:53.249+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:05:53.269+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.057 seconds
[2022-11-21T20:06:23.364+0000] {processor.py:154} INFO - Started process (PID=16353) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:06:23.368+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:06:23.370+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:06:23.370+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:06:23.406+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:06:23.404+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:06:23.407+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:06:23.431+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.072 seconds
[2022-11-21T20:06:54.060+0000] {processor.py:154} INFO - Started process (PID=16377) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:06:54.064+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:06:54.068+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:06:54.067+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:06:54.101+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:06:54.097+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:06:54.116+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:06:54.141+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.087 seconds
[2022-11-21T20:07:24.681+0000] {processor.py:154} INFO - Started process (PID=16410) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:07:24.685+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:07:24.687+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:07:24.687+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:07:24.761+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:07:24.754+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:07:24.766+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:07:24.795+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.120 seconds
[2022-11-21T20:07:55.342+0000] {processor.py:154} INFO - Started process (PID=16442) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:07:55.345+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:07:55.348+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:07:55.348+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:07:55.389+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:07:55.386+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:07:55.392+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:07:55.419+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.084 seconds
[2022-11-21T20:08:25.893+0000] {processor.py:154} INFO - Started process (PID=16475) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:08:25.896+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:08:25.897+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:08:25.897+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:08:25.927+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:08:25.924+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:08:25.930+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:08:25.952+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.063 seconds
[2022-11-21T20:08:56.459+0000] {processor.py:154} INFO - Started process (PID=16508) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:08:56.463+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:08:56.467+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:08:56.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:08:56.543+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:08:56.534+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:08:56.546+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:08:56.582+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.130 seconds
[2022-11-21T20:09:27.263+0000] {processor.py:154} INFO - Started process (PID=16532) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:09:27.266+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:09:27.268+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:09:27.268+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:09:27.322+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:09:27.319+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:09:27.324+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:09:27.352+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.099 seconds
[2022-11-21T20:09:57.896+0000] {processor.py:154} INFO - Started process (PID=16565) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:09:57.900+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:09:57.902+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:09:57.902+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:09:57.932+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:09:57.930+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:09:57.934+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:09:57.969+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.080 seconds
[2022-11-21T20:10:28.625+0000] {processor.py:154} INFO - Started process (PID=16598) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:10:28.629+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:10:28.632+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:10:28.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:10:28.689+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:10:28.683+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:10:28.691+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:10:28.717+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.100 seconds
[2022-11-21T20:10:59.206+0000] {processor.py:154} INFO - Started process (PID=16632) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:10:59.209+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:10:59.212+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:10:59.212+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:10:59.240+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:10:59.237+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:10:59.242+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:10:59.265+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.064 seconds
[2022-11-21T20:11:29.770+0000] {processor.py:154} INFO - Started process (PID=16665) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:11:29.774+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:11:29.777+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:11:29.777+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:11:29.835+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:11:29.821+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'password', 'port', 'user'
[2022-11-21T20:11:29.838+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:11:29.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.105 seconds
[2022-11-21T20:12:00.611+0000] {processor.py:154} INFO - Started process (PID=16688) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:12:00.615+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:12:00.618+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:12:00.618+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:12:00.686+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:12:00.682+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:12:00.687+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:12:00.707+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.100 seconds
[2022-11-21T20:12:31.207+0000] {processor.py:154} INFO - Started process (PID=16718) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:12:31.211+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:12:31.213+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:12:31.213+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:12:31.253+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:12:31.250+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:12:31.254+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:12:31.275+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.073 seconds
[2022-11-21T20:13:01.814+0000] {processor.py:154} INFO - Started process (PID=16751) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:13:01.818+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:13:01.821+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:13:01.821+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:13:01.856+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:13:01.853+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:13:01.863+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:13:01.887+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.080 seconds
[2022-11-21T20:13:32.449+0000] {processor.py:154} INFO - Started process (PID=16782) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:13:32.452+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:13:32.454+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:13:32.454+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:13:32.475+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:13:32.472+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:13:32.476+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:13:32.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.055 seconds
[2022-11-21T20:14:03.082+0000] {processor.py:154} INFO - Started process (PID=16815) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:14:03.086+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:14:03.091+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:14:03.091+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:14:03.144+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:14:03.134+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:14:03.153+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:14:03.189+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.111 seconds
[2022-11-21T20:14:33.751+0000] {processor.py:154} INFO - Started process (PID=16839) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:14:33.754+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:14:33.756+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:14:33.755+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:14:33.793+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:14:33.790+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:14:33.795+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:14:33.815+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.070 seconds
[2022-11-21T20:15:04.442+0000] {processor.py:154} INFO - Started process (PID=16872) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:15:04.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:15:04.453+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:15:04.452+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:15:04.477+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:15:04.474+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:15:04.479+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:15:04.503+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.068 seconds
[2022-11-21T20:15:35.057+0000] {processor.py:154} INFO - Started process (PID=16906) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:15:35.061+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:15:35.064+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:15:35.064+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:15:35.095+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:15:35.090+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:15:35.098+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:15:35.123+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.073 seconds
[2022-11-21T20:16:05.160+0000] {processor.py:154} INFO - Started process (PID=16937) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:16:05.162+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:16:05.163+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:16:05.163+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:16:05.198+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:16:05.180+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:16:05.200+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:16:05.221+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.064 seconds
[2022-11-21T20:16:35.724+0000] {processor.py:154} INFO - Started process (PID=16961) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:16:35.726+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:16:35.728+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:16:35.728+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:16:35.756+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:16:35.752+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:16:35.759+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:16:35.782+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.062 seconds
[2022-11-21T20:17:06.405+0000] {processor.py:154} INFO - Started process (PID=16993) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:17:06.408+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:17:06.409+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:17:06.409+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:17:06.433+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:17:06.429+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:17:06.435+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:17:06.457+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.057 seconds
[2022-11-21T20:17:36.652+0000] {processor.py:154} INFO - Started process (PID=17025) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:17:36.656+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:17:36.658+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:17:36.658+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:17:36.697+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:17:36.685+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in PostgresToS3Operator
    service_name:str, region_name:str, access_key: str, secret_access_key: str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:17:36.700+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:17:36.727+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.081 seconds
[2022-11-21T20:18:07.561+0000] {processor.py:154} INFO - Started process (PID=17059) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:18:07.583+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:18:07.605+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:18:07.604+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:18:07.806+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:18:07.790+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:18:07.818+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:18:07.893+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.347 seconds
[2022-11-21T20:18:38.768+0000] {processor.py:154} INFO - Started process (PID=17083) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:18:38.772+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:18:38.775+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:18:38.775+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:18:38.823+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:18:38.815+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:18:38.827+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:18:38.860+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.100 seconds
[2022-11-21T20:19:09.509+0000] {processor.py:154} INFO - Started process (PID=17117) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:19:09.514+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:19:09.517+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:19:09.517+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:19:09.624+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:19:09.616+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:19:09.627+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:19:09.682+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.188 seconds
[2022-11-21T20:19:39.772+0000] {processor.py:154} INFO - Started process (PID=17150) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:19:39.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:19:39.778+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:19:39.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:19:39.824+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:19:39.806+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:19:39.827+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:19:39.851+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.085 seconds
[2022-11-21T20:20:10.663+0000] {processor.py:154} INFO - Started process (PID=17183) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:20:10.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:20:10.674+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:20:10.674+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:20:10.745+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:20:10.736+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:20:10.752+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:20:10.803+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.144 seconds
[2022-11-21T20:20:41.034+0000] {processor.py:154} INFO - Started process (PID=17206) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:20:41.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:20:41.043+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:20:41.043+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:20:41.087+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:20:41.080+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:20:41.093+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:20:41.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.111 seconds
[2022-11-21T20:21:11.590+0000] {processor.py:154} INFO - Started process (PID=17238) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:21:11.595+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:21:11.601+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:21:11.601+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:21:11.634+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:21:11.631+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:21:11.636+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:21:11.661+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.080 seconds
[2022-11-21T20:21:41.825+0000] {processor.py:154} INFO - Started process (PID=17271) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:21:41.833+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:21:41.836+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:21:41.836+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:21:41.904+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:21:41.897+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:21:41.910+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:21:41.942+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.123 seconds
[2022-11-21T20:22:12.169+0000] {processor.py:154} INFO - Started process (PID=17294) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:22:12.184+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:22:12.191+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:22:12.191+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:22:12.339+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:22:12.318+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    )
    ^
SyntaxError: invalid syntax
[2022-11-21T20:22:12.347+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:22:12.446+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.289 seconds
[2022-11-21T20:22:42.536+0000] {processor.py:154} INFO - Started process (PID=17325) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:22:42.541+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:22:42.543+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:22:42.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:22:42.608+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:22:42.602+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    )
    ^
SyntaxError: invalid syntax
[2022-11-21T20:22:42.610+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:22:42.635+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.104 seconds
[2022-11-21T20:23:13.276+0000] {processor.py:154} INFO - Started process (PID=17358) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:23:13.279+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:23:13.281+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:23:13.281+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:23:13.347+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:23:13.344+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:23:13.349+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:23:13.371+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.102 seconds
[2022-11-21T20:23:43.520+0000] {processor.py:154} INFO - Started process (PID=17390) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:23:43.524+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:23:43.527+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:23:43.527+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:23:43.649+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:23:43.637+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:23:43.652+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:23:43.690+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.174 seconds
[2022-11-21T20:24:13.912+0000] {processor.py:154} INFO - Started process (PID=17414) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:24:13.917+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:24:13.919+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:24:13.919+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:24:13.947+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:24:13.943+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:24:13.948+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:24:13.967+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.060 seconds
[2022-11-21T20:24:44.054+0000] {processor.py:154} INFO - Started process (PID=17446) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:24:44.057+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:24:44.058+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:24:44.058+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:24:44.120+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:24:44.117+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:24:44.122+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:24:44.145+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.097 seconds
[2022-11-21T20:25:14.639+0000] {processor.py:154} INFO - Started process (PID=17479) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:25:14.642+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:25:14.644+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:25:14.644+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:25:14.713+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:25:14.708+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:25:14.715+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:25:14.739+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.105 seconds
[2022-11-21T20:25:45.119+0000] {processor.py:154} INFO - Started process (PID=17503) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:25:45.134+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:25:45.138+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:25:45.137+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:25:45.233+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:25:45.229+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:25:45.236+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:25:45.276+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.196 seconds
[2022-11-21T20:26:15.904+0000] {processor.py:154} INFO - Started process (PID=17535) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:26:15.906+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:26:15.910+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:26:15.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:26:15.936+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:26:15.933+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:26:15.938+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:26:15.956+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.056 seconds
[2022-11-21T20:26:46.306+0000] {processor.py:154} INFO - Started process (PID=17567) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:26:46.311+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:26:46.314+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:26:46.314+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:26:46.351+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:26:46.347+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:26:46.356+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:26:46.383+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.087 seconds
[2022-11-21T20:27:17.189+0000] {processor.py:154} INFO - Started process (PID=17591) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:27:17.201+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:27:17.209+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:27:17.209+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:27:17.369+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:27:17.310+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:27:17.379+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:27:17.486+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.326 seconds
[2022-11-21T20:27:47.715+0000] {processor.py:154} INFO - Started process (PID=17623) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:27:47.718+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:27:47.720+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:27:47.720+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:27:47.763+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:27:47.760+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:27:47.764+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:27:47.802+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.093 seconds
[2022-11-21T20:28:17.923+0000] {processor.py:154} INFO - Started process (PID=17656) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:28:17.927+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:28:17.947+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:28:17.946+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:28:17.981+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:28:17.978+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:28:17.983+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:28:18.003+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.086 seconds
[2022-11-21T20:28:48.242+0000] {processor.py:154} INFO - Started process (PID=17687) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:28:48.252+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:28:48.258+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:28:48.258+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:28:48.557+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:28:48.545+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:28:48.566+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:28:48.635+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.400 seconds
[2022-11-21T20:29:18.799+0000] {processor.py:154} INFO - Started process (PID=17713) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:29:18.815+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:29:18.819+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:29:18.819+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:29:19.019+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:29:19.006+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:29:19.024+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:29:19.101+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.317 seconds
[2022-11-21T20:29:49.176+0000] {processor.py:154} INFO - Started process (PID=17746) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:29:49.180+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:29:49.182+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:29:49.182+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:29:49.209+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:29:49.206+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 4, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:29:49.210+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:29:49.230+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.059 seconds
[2022-11-21T20:30:19.342+0000] {processor.py:154} INFO - Started process (PID=17779) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:30:19.350+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:30:19.354+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:30:19.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:30:19.777+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:30:19.763+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:30:19.793+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:30:19.853+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.517 seconds
[2022-11-21T20:30:50.280+0000] {processor.py:154} INFO - Started process (PID=17804) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:30:50.282+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:30:50.298+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:30:50.298+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:30:50.772+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:30:50.741+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:30:50.779+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:30:50.837+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.562 seconds
[2022-11-21T20:31:21.036+0000] {processor.py:154} INFO - Started process (PID=17838) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:31:21.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:31:21.041+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:31:21.041+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:31:21.189+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:31:21.182+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:31:21.192+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:31:21.213+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.182 seconds
[2022-11-21T20:31:51.401+0000] {processor.py:154} INFO - Started process (PID=17872) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:31:51.405+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:31:51.408+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:31:51.408+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:31:51.563+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:31:51.556+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:31:51.569+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:31:51.590+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.194 seconds
[2022-11-21T20:32:22.538+0000] {processor.py:154} INFO - Started process (PID=17906) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:32:22.547+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:32:22.559+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:32:22.558+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:32:23.736+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:32:23.718+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:32:23.742+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:32:23.815+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 1.310 seconds
[2022-11-21T20:32:53.979+0000] {processor.py:154} INFO - Started process (PID=17931) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:32:53.981+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:32:53.983+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:32:53.983+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:32:54.172+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:32:54.167+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:32:54.174+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:32:54.198+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.224 seconds
[2022-11-21T20:33:24.787+0000] {processor.py:154} INFO - Started process (PID=17964) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:33:24.791+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:33:24.794+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:33:24.793+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:33:24.959+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:33:24.952+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:33:24.962+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:33:24.982+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.199 seconds
[2022-11-21T20:33:55.369+0000] {processor.py:154} INFO - Started process (PID=17996) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:33:55.372+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:33:55.374+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:33:55.374+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:33:55.527+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:33:55.521+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:33:55.530+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:33:55.551+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.189 seconds
[2022-11-21T20:34:26.150+0000] {processor.py:154} INFO - Started process (PID=18029) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:34:26.155+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:34:26.161+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:34:26.160+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:34:26.514+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:34:26.501+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:34:26.525+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:34:26.596+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.452 seconds
[2022-11-21T20:34:56.944+0000] {processor.py:154} INFO - Started process (PID=18054) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:34:56.949+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:34:56.969+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:34:56.968+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:34:57.114+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:34:57.109+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:34:57.116+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:34:57.134+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.196 seconds
[2022-11-21T20:35:27.311+0000] {processor.py:154} INFO - Started process (PID=18088) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:35:27.314+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:35:27.316+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:35:27.316+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:35:27.470+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:35:27.464+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:35:27.472+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:35:27.493+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.188 seconds
[2022-11-21T20:35:57.627+0000] {processor.py:154} INFO - Started process (PID=18121) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:35:57.631+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:35:57.633+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:35:57.633+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:35:57.781+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:35:57.776+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:35:57.783+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:35:57.804+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.184 seconds
[2022-11-21T20:36:28.525+0000] {processor.py:154} INFO - Started process (PID=18154) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:36:28.530+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:36:28.532+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:36:28.532+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:36:28.839+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:36:28.832+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:36:28.840+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:36:28.872+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.353 seconds
[2022-11-21T20:36:59.542+0000] {processor.py:154} INFO - Started process (PID=18179) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:36:59.558+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:36:59.560+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:36:59.560+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:36:59.759+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:36:59.753+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:36:59.762+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:36:59.785+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.248 seconds
[2022-11-21T20:37:30.390+0000] {processor.py:154} INFO - Started process (PID=18212) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:37:30.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:37:30.394+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:37:30.394+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:37:30.627+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:37:30.613+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 5, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 8, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:37:30.633+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:37:30.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.273 seconds
[2022-11-21T20:38:01.177+0000] {processor.py:154} INFO - Started process (PID=18245) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:38:01.182+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:38:01.185+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:38:01.185+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:38:01.620+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:38:01.614+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 9, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:38:01.621+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:38:01.640+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.468 seconds
[2022-11-21T20:38:31.974+0000] {processor.py:154} INFO - Started process (PID=18279) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:38:31.976+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:38:31.978+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:38:31.978+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:38:32.354+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:38:32.346+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 9, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:38:32.358+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:38:32.377+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.407 seconds
[2022-11-21T20:39:02.792+0000] {processor.py:154} INFO - Started process (PID=18303) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:39:02.796+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:39:02.799+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:39:02.799+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:39:03.169+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:39:03.163+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 9, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:39:03.174+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:39:03.192+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.407 seconds
[2022-11-21T20:39:33.332+0000] {processor.py:154} INFO - Started process (PID=18339) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:39:33.334+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:39:33.336+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:39:33.336+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:39:33.787+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:39:33.781+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 9, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:39:33.788+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:39:33.806+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.482 seconds
[2022-11-21T20:40:03.978+0000] {processor.py:154} INFO - Started process (PID=18376) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:40:03.989+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:40:03.991+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:40:03.991+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:40:04.358+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:40:04.351+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:40:04.364+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:40:04.383+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.410 seconds
[2022-11-21T20:40:34.914+0000] {processor.py:154} INFO - Started process (PID=18409) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:40:34.920+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:40:34.926+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:40:34.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:40:35.411+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:40:35.404+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:40:35.414+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:40:35.432+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.525 seconds
[2022-11-21T20:41:06.008+0000] {processor.py:154} INFO - Started process (PID=18431) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:41:06.011+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:41:06.013+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:41:06.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:41:06.592+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:41:06.584+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:41:06.595+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:41:06.626+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.622 seconds
[2022-11-21T20:41:37.363+0000] {processor.py:154} INFO - Started process (PID=18465) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:41:37.366+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:41:37.369+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:41:37.369+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:41:37.871+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:41:37.865+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:41:37.873+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:41:37.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.536 seconds
[2022-11-21T20:42:08.016+0000] {processor.py:154} INFO - Started process (PID=18499) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:42:08.023+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:42:08.025+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:42:08.025+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:42:08.632+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:42:08.625+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:42:08.635+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:42:08.660+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.654 seconds
[2022-11-21T20:42:39.389+0000] {processor.py:154} INFO - Started process (PID=18532) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:42:39.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:42:39.395+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:42:39.395+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:42:39.878+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:42:39.872+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:42:39.897+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:42:39.920+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.537 seconds
[2022-11-21T20:43:10.116+0000] {processor.py:154} INFO - Started process (PID=18558) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:43:10.119+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:43:10.121+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:43:10.121+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:43:10.846+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:43:10.829+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:43:10.857+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:43:10.907+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.797 seconds
[2022-11-21T20:43:41.735+0000] {processor.py:154} INFO - Started process (PID=18591) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:43:41.738+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:43:41.741+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:43:41.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:43:42.117+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:43:42.109+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:43:42.119+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:43:42.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.433 seconds
[2022-11-21T20:44:12.767+0000] {processor.py:154} INFO - Started process (PID=18625) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:44:12.772+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:44:12.777+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:44:12.776+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:44:13.319+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:44:13.312+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:44:13.321+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:44:13.345+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.587 seconds
[2022-11-21T20:44:43.970+0000] {processor.py:154} INFO - Started process (PID=18659) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:44:43.973+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:44:43.974+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:44:43.974+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:44:44.389+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:44:44.381+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:44:44.391+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:44:44.412+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.447 seconds
[2022-11-21T20:45:15.183+0000] {processor.py:154} INFO - Started process (PID=18692) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:45:15.186+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:45:15.191+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:45:15.190+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:45:15.734+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:45:15.728+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:45:15.736+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:45:15.759+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.582 seconds
[2022-11-21T20:45:46.508+0000] {processor.py:154} INFO - Started process (PID=18718) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:45:46.515+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:45:46.518+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:45:46.518+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:45:47.433+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:45:47.414+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:45:47.439+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:45:47.516+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 1.023 seconds
[2022-11-21T20:46:18.292+0000] {processor.py:154} INFO - Started process (PID=18753) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:46:18.306+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:46:18.311+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:46:18.310+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:46:19.068+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:46:19.062+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:46:19.070+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:46:19.093+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.807 seconds
[2022-11-21T20:46:49.733+0000] {processor.py:154} INFO - Started process (PID=18787) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:46:49.741+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:46:49.743+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:46:49.742+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:46:50.283+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:46:50.274+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:46:50.289+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:46:50.323+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.597 seconds
[2022-11-21T20:47:21.343+0000] {processor.py:154} INFO - Started process (PID=18821) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:47:21.346+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:47:21.353+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:47:21.352+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:47:21.847+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:47:21.841+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:47:21.849+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:47:21.869+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.536 seconds
[2022-11-21T20:47:52.733+0000] {processor.py:154} INFO - Started process (PID=18855) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:47:52.738+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:47:52.740+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:47:52.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:47:53.335+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:47:53.316+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:47:53.339+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:47:53.363+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.635 seconds
[2022-11-21T20:48:23.561+0000] {processor.py:154} INFO - Started process (PID=18880) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:48:23.570+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:48:23.575+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:48:23.574+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:48:24.333+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:48:24.317+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:48:24.339+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:48:24.391+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.838 seconds
[2022-11-21T20:48:55.282+0000] {processor.py:154} INFO - Started process (PID=18913) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:48:55.286+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:48:55.288+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:48:55.288+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:48:55.722+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:48:55.717+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:48:55.727+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:48:55.749+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.472 seconds
[2022-11-21T20:49:26.327+0000] {processor.py:154} INFO - Started process (PID=18946) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:49:26.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:49:26.334+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:49:26.334+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:49:26.822+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:49:26.815+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:49:26.824+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:49:26.848+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.527 seconds
[2022-11-21T20:49:57.647+0000] {processor.py:154} INFO - Started process (PID=18983) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:49:57.650+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:49:57.652+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:49:57.652+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:49:58.211+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:49:58.202+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:49:58.213+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:49:58.245+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.603 seconds
[2022-11-21T20:50:28.890+0000] {processor.py:154} INFO - Started process (PID=19018) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:50:28.895+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:50:28.896+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:50:28.896+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:50:29.264+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:50:29.256+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:50:29.268+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:50:29.292+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.405 seconds
[2022-11-21T20:50:59.908+0000] {processor.py:154} INFO - Started process (PID=19043) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:50:59.912+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:50:59.913+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:50:59.913+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:51:00.318+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:51:00.310+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:51:00.321+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:51:00.342+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.439 seconds
[2022-11-21T20:51:31.011+0000] {processor.py:154} INFO - Started process (PID=19077) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:51:31.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:51:31.017+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:51:31.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:51:31.349+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:51:31.341+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:51:31.352+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:51:31.372+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.367 seconds
[2022-11-21T20:52:02.187+0000] {processor.py:154} INFO - Started process (PID=19110) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:52:02.190+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:52:02.192+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:52:02.192+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:52:02.695+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:52:02.688+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:52:02.697+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:52:02.726+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.543 seconds
[2022-11-21T20:52:33.562+0000] {processor.py:154} INFO - Started process (PID=19144) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:52:33.565+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:52:33.567+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:52:33.567+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:52:34.044+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:52:34.024+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:52:34.048+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:52:34.070+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.512 seconds
[2022-11-21T20:53:05.005+0000] {processor.py:154} INFO - Started process (PID=19178) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:53:05.013+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:53:05.018+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:53:05.018+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:53:06.127+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:53:06.113+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:53:06.134+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:53:06.171+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 1.178 seconds
[2022-11-21T20:53:36.877+0000] {processor.py:154} INFO - Started process (PID=19203) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:53:36.880+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:53:36.882+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:53:36.882+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:53:37.554+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:53:37.543+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:53:37.557+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:53:37.600+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.729 seconds
[2022-11-21T20:54:08.241+0000] {processor.py:154} INFO - Started process (PID=19237) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:54:08.249+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:54:08.254+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:54:08.254+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:54:09.025+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:54:09.010+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:54:09.029+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:54:09.062+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.836 seconds
[2022-11-21T20:54:39.807+0000] {processor.py:154} INFO - Started process (PID=19271) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:54:39.810+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:54:39.815+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:54:39.815+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:54:40.305+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:54:40.298+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in PostgresToS3Operator
    secret_access_key: str, sql:str **kwargs) :
NameError: name 'kwargs' is not defined
[2022-11-21T20:54:40.306+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:54:40.330+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.531 seconds
[2022-11-21T20:55:10.824+0000] {processor.py:154} INFO - Started process (PID=19305) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:55:10.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:55:10.830+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:55:10.830+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:55:11.394+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:55:11.390+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'service_name', 'sql', 'user'
[2022-11-21T20:55:11.398+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:55:11.428+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.609 seconds
[2022-11-21T20:55:42.045+0000] {processor.py:154} INFO - Started process (PID=19339) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:55:42.052+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:55:42.058+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:55:42.058+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:55:42.875+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:55:42.872+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'service_name', 'sql', 'user'
[2022-11-21T20:55:42.878+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:55:42.901+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.862 seconds
[2022-11-21T20:56:13.720+0000] {processor.py:154} INFO - Started process (PID=19364) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:56:13.723+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:56:13.725+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:56:13.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:56:14.237+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:56:14.234+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'service_name', 'sql', 'user'
[2022-11-21T20:56:14.240+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:56:14.270+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.554 seconds
[2022-11-21T20:56:45.044+0000] {processor.py:154} INFO - Started process (PID=19398) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:56:45.047+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:56:45.051+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:56:45.051+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:56:45.507+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:56:45.504+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T20:56:45.509+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:56:45.531+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.492 seconds
[2022-11-21T20:57:16.465+0000] {processor.py:154} INFO - Started process (PID=19433) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:57:16.470+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:57:16.472+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:57:16.472+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:57:16.969+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:57:16.966+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T20:57:16.972+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:57:16.997+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.538 seconds
[2022-11-21T20:57:47.808+0000] {processor.py:154} INFO - Started process (PID=19469) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:57:47.811+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:57:47.813+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:57:47.813+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:57:47.929+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:57:47.925+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T20:57:47.932+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:57:47.959+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.158 seconds
[2022-11-21T20:58:18.679+0000] {processor.py:154} INFO - Started process (PID=19503) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:58:18.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:58:18.686+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:58:18.686+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:58:18.799+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:58:18.796+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T20:58:18.801+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:58:18.827+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.154 seconds
[2022-11-21T20:58:49.761+0000] {processor.py:154} INFO - Started process (PID=19527) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:58:49.777+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:58:49.791+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:58:49.790+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:58:50.129+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:58:50.114+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T20:58:50.136+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:58:50.395+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.659 seconds
[2022-11-21T20:59:21.410+0000] {processor.py:154} INFO - Started process (PID=19558) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:59:21.415+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:59:21.420+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:59:21.420+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:59:21.558+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:59:21.547+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T20:59:21.587+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:59:21.645+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.248 seconds
[2022-11-21T20:59:52.104+0000] {processor.py:154} INFO - Started process (PID=19591) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:59:52.109+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T20:59:52.114+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:59:52.113+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:59:52.267+0000] {logging_mixin.py:120} INFO - [2022-11-21T20:59:52.263+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T20:59:52.273+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T20:59:52.299+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.202 seconds
[2022-11-21T21:00:22.451+0000] {processor.py:154} INFO - Started process (PID=19624) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:00:22.460+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:00:22.465+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:00:22.465+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:00:22.577+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:00:22.572+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:00:22.580+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:00:22.622+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.179 seconds
[2022-11-21T21:00:52.763+0000] {processor.py:154} INFO - Started process (PID=19648) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:00:52.766+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:00:52.768+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:00:52.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:00:52.865+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:00:52.860+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:00:52.867+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:00:52.889+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.134 seconds
[2022-11-21T21:01:23.120+0000] {processor.py:154} INFO - Started process (PID=19681) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:01:23.127+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:01:23.135+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:01:23.134+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:01:23.510+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:01:23.502+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:01:23.514+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:01:23.558+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.449 seconds
[2022-11-21T21:01:53.632+0000] {processor.py:154} INFO - Started process (PID=19714) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:01:53.635+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:01:53.636+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:01:53.636+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:01:53.754+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:01:53.750+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:01:53.760+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:01:53.874+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.249 seconds
[2022-11-21T21:02:24.359+0000] {processor.py:154} INFO - Started process (PID=19748) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:02:24.366+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:02:24.369+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:02:24.369+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:02:24.518+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:02:24.510+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:02:24.522+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:02:24.555+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.199 seconds
[2022-11-21T21:02:55.473+0000] {processor.py:154} INFO - Started process (PID=19771) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:02:55.478+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:02:55.480+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:02:55.480+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:02:55.652+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:02:55.620+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:02:55.664+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:02:55.714+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.251 seconds
[2022-11-21T21:03:26.592+0000] {processor.py:154} INFO - Started process (PID=19804) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:03:26.596+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:03:26.599+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:03:26.599+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:03:26.700+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:03:26.696+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:03:26.702+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:03:26.726+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.142 seconds
[2022-11-21T21:03:56.845+0000] {processor.py:154} INFO - Started process (PID=19838) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:03:56.848+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:03:56.855+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:03:56.855+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:03:56.951+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:03:56.947+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:03:56.955+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:03:56.982+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.143 seconds
[2022-11-21T21:04:27.779+0000] {processor.py:154} INFO - Started process (PID=19872) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:04:27.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:04:27.792+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:04:27.792+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:04:28.030+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:04:28.024+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:04:28.038+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:04:28.085+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.316 seconds
[2022-11-21T21:04:58.783+0000] {processor.py:154} INFO - Started process (PID=19897) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:04:58.788+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:04:58.790+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:04:58.789+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:04:58.896+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:04:58.892+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:04:58.898+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:04:58.922+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.144 seconds
[2022-11-21T21:05:29.862+0000] {processor.py:154} INFO - Started process (PID=19930) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:05:29.865+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:05:29.868+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:05:29.868+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:05:29.965+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:05:29.957+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:05:29.968+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:05:29.995+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.140 seconds
[2022-11-21T21:06:00.894+0000] {processor.py:154} INFO - Started process (PID=19962) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:00.897+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:06:00.899+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:06:00.899+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:00.997+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:06:00.994+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 21, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    raise AirflowException(f"missing keyword arguments {display}")
airflow.exceptions.AirflowException: missing keyword arguments 'access_key', 'bucket', 'database', 'filename', 'password', 'port', 'region_name', 'secret_access_key', 'sql', 'user'
[2022-11-21T21:06:01.001+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:01.022+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.133 seconds
[2022-11-21T21:06:04.288+0000] {processor.py:154} INFO - Started process (PID=19964) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:04.313+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:06:04.329+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:06:04.329+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:04.359+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:06:04.358+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    self.host = host
       ^
SyntaxError: invalid syntax
[2022-11-21T21:06:04.362+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:04.398+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.177 seconds
[2022-11-21T21:06:35.156+0000] {processor.py:154} INFO - Started process (PID=19997) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:35.159+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:06:35.160+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:06:35.160+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:35.174+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:06:35.173+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    self.host = host
       ^
SyntaxError: invalid syntax
[2022-11-21T21:06:35.176+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:06:35.199+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.046 seconds
[2022-11-21T21:07:05.726+0000] {processor.py:154} INFO - Started process (PID=20032) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:07:05.727+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:07:05.729+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:07:05.729+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:07:05.743+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:07:05.741+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    self.host = host
       ^
SyntaxError: invalid syntax
[2022-11-21T21:07:05.744+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:07:05.768+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.045 seconds
[2022-11-21T21:07:36.426+0000] {processor.py:154} INFO - Started process (PID=20056) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:07:36.430+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:07:36.433+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:07:36.433+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:07:36.457+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:07:36.455+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    self.host = host
       ^
SyntaxError: invalid syntax
[2022-11-21T21:07:36.463+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:07:36.509+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.089 seconds
[2022-11-21T21:08:07.016+0000] {processor.py:154} INFO - Started process (PID=20089) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:08:07.019+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:08:07.022+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:08:07.022+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:08:07.036+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:08:07.035+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    self.host = host
       ^
SyntaxError: invalid syntax
[2022-11-21T21:08:07.038+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:08:07.064+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.055 seconds
[2022-11-21T21:08:36.297+0000] {processor.py:154} INFO - Started process (PID=20121) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:08:36.301+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:08:36.308+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:08:36.308+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:08:36.420+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:08:36.416+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20, in <module>
    host = host,
NameError: name 'host' is not defined
[2022-11-21T21:08:36.423+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:08:36.453+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.164 seconds
[2022-11-21T21:09:06.730+0000] {processor.py:154} INFO - Started process (PID=20154) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:06.738+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:09:06.741+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:09:06.741+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:06.890+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:09:06.886+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20, in <module>
    host = host,
NameError: name 'host' is not defined
[2022-11-21T21:09:06.893+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:06.918+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.194 seconds
[2022-11-21T21:09:23.988+0000] {processor.py:154} INFO - Started process (PID=20168) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:23.993+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:09:23.995+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:09:23.995+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:24.135+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:09:24.133+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 24, in <module>
    region_name = region_name,
NameError: name 'region_name' is not defined
[2022-11-21T21:09:24.137+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:24.159+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.176 seconds
[2022-11-21T21:09:54.409+0000] {processor.py:154} INFO - Started process (PID=20201) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:54.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:09:54.417+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:09:54.417+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:54.524+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:09:54.497+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 24, in <module>
    region_name = region_name,
NameError: name 'region_name' is not defined
[2022-11-21T21:09:54.558+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:09:54.720+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.318 seconds
[2022-11-21T21:10:02.549+0000] {processor.py:154} INFO - Started process (PID=20208) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:10:02.561+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:10:02.564+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:10:02.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:10:02.777+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:10:02.772+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:10:02.782+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:10:02.861+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.319 seconds
[2022-11-21T21:10:33.137+0000] {processor.py:154} INFO - Started process (PID=20234) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:10:33.141+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:10:33.142+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:10:33.142+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:10:33.211+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:10:33.208+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:10:33.213+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:10:33.236+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.112 seconds
[2022-11-21T21:11:03.875+0000] {processor.py:154} INFO - Started process (PID=20268) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:11:03.878+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:11:03.880+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:11:03.880+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:11:03.953+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:11:03.949+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:11:03.956+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:11:03.979+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.111 seconds
[2022-11-21T21:11:34.332+0000] {processor.py:154} INFO - Started process (PID=20300) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:11:34.337+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:11:34.339+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:11:34.339+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:11:34.434+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:11:34.430+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:11:34.436+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:11:34.475+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.148 seconds
[2022-11-21T21:12:04.877+0000] {processor.py:154} INFO - Started process (PID=20326) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:12:04.880+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:12:04.882+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:12:04.882+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:12:04.958+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:12:04.955+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:12:04.959+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:12:04.981+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.109 seconds
[2022-11-21T21:12:35.255+0000] {processor.py:154} INFO - Started process (PID=20359) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:12:35.257+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:12:35.258+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:12:35.258+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:12:35.315+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:12:35.313+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:12:35.329+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:12:35.351+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.100 seconds
[2022-11-21T21:13:05.397+0000] {processor.py:154} INFO - Started process (PID=20392) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:13:05.402+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:13:05.409+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:13:05.408+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:13:05.497+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:13:05.492+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:13:05.500+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:13:05.525+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.132 seconds
[2022-11-21T21:13:35.705+0000] {processor.py:154} INFO - Started process (PID=20416) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:13:35.708+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:13:35.710+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:13:35.709+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:13:35.768+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:13:35.765+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:13:35.770+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:13:35.790+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.088 seconds
[2022-11-21T21:14:06.349+0000] {processor.py:154} INFO - Started process (PID=20448) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:06.352+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:14:06.354+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:06.354+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:06.460+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:06.456+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:14:06.462+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:06.501+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.159 seconds
[2022-11-21T21:14:36.822+0000] {processor.py:154} INFO - Started process (PID=20479) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:36.826+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:14:36.833+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:36.833+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:36.903+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:36.899+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:14:36.905+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:36.926+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.111 seconds
[2022-11-21T21:14:46.173+0000] {processor.py:154} INFO - Started process (PID=20491) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:46.177+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:14:46.181+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:46.181+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:46.459+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:46.450+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:14:46.462+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:46.519+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.352 seconds
[2022-11-21T21:14:59.558+0000] {processor.py:154} INFO - Started process (PID=20504) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:59.561+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:14:59.564+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:59.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:59.674+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:14:59.672+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:14:59.677+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:14:59.712+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.158 seconds
[2022-11-21T21:15:30.134+0000] {processor.py:154} INFO - Started process (PID=20527) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:15:30.139+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:15:30.161+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:15:30.161+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:15:30.282+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:15:30.278+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:15:30.286+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:15:30.316+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.187 seconds
[2022-11-21T21:15:34.416+0000] {processor.py:154} INFO - Started process (PID=20537) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:15:34.424+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:15:34.428+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:15:34.428+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:15:34.609+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:15:34.604+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:15:34.611+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:15:34.651+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.248 seconds
[2022-11-21T21:16:04.987+0000] {processor.py:154} INFO - Started process (PID=20570) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:04.992+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:16:04.996+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:16:04.996+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:05.198+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:16:05.193+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:16:05.202+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:05.237+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.258 seconds
[2022-11-21T21:16:35.555+0000] {processor.py:154} INFO - Started process (PID=20594) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:35.557+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:16:35.559+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:16:35.559+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:35.624+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:16:35.621+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:16:35.631+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:35.655+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.105 seconds
[2022-11-21T21:16:41.635+0000] {processor.py:154} INFO - Started process (PID=20603) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:41.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:16:41.644+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:16:41.644+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:41.806+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:16:41.801+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:16:41.808+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:16:41.834+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.211 seconds
[2022-11-21T21:17:01.038+0000] {processor.py:154} INFO - Started process (PID=20615) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:01.049+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:17:01.060+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:17:01.059+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:01.517+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:17:01.505+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:17:01.523+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:01.610+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.619 seconds
[2022-11-21T21:17:32.300+0000] {processor.py:154} INFO - Started process (PID=20649) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:32.303+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:17:32.304+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:17:32.304+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:32.379+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:17:32.376+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 25, in <module>
    access_key =access_key,
NameError: name 'access_key' is not defined
[2022-11-21T21:17:32.381+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:32.404+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.108 seconds
[2022-11-21T21:17:51.823+0000] {processor.py:154} INFO - Started process (PID=20672) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:51.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:17:51.829+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:17:51.829+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:51.953+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:17:51.947+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:17:51.955+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:17:51.979+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.161 seconds
[2022-11-21T21:18:22.567+0000] {processor.py:154} INFO - Started process (PID=20703) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:18:22.569+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:18:22.572+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:18:22.572+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:18:22.656+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:18:22.647+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:18:22.658+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:18:22.686+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.122 seconds
[2022-11-21T21:18:53.257+0000] {processor.py:154} INFO - Started process (PID=20727) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:18:53.263+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:18:53.266+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:18:53.265+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:18:53.357+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:18:53.349+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:18:53.359+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:18:53.384+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.132 seconds
[2022-11-21T21:19:23.497+0000] {processor.py:154} INFO - Started process (PID=20759) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:19:23.500+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:19:23.502+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:19:23.502+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:19:23.576+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:19:23.571+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:19:23.579+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:19:23.599+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.107 seconds
[2022-11-21T21:19:53.983+0000] {processor.py:154} INFO - Started process (PID=20791) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:19:53.987+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:19:53.989+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:19:53.989+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:19:54.063+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:19:54.059+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:19:54.066+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:19:54.087+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.109 seconds
[2022-11-21T21:20:24.328+0000] {processor.py:154} INFO - Started process (PID=20825) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:20:24.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:20:24.348+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:20:24.348+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:20:24.452+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:20:24.442+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:20:24.456+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:20:24.485+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.162 seconds
[2022-11-21T21:20:55.425+0000] {processor.py:154} INFO - Started process (PID=20850) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:20:55.429+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:20:55.430+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:20:55.430+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:20:55.507+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:20:55.497+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:20:55.509+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:20:55.534+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.112 seconds
[2022-11-21T21:21:25.920+0000] {processor.py:154} INFO - Started process (PID=20883) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:21:25.925+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:21:25.927+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:21:25.927+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:21:26.058+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:21:26.045+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:21:26.063+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:21:26.099+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.187 seconds
[2022-11-21T21:21:56.275+0000] {processor.py:154} INFO - Started process (PID=20915) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:21:56.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:21:56.280+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:21:56.280+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:21:56.369+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:21:56.361+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:21:56.371+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:21:56.392+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.124 seconds
[2022-11-21T21:22:26.961+0000] {processor.py:154} INFO - Started process (PID=20948) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:22:26.964+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:22:26.966+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:22:26.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:22:27.037+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:22:27.023+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:22:27.041+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:22:27.063+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.108 seconds
[2022-11-21T21:22:57.180+0000] {processor.py:154} INFO - Started process (PID=20971) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:22:57.184+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:22:57.187+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:22:57.187+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:22:57.279+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:22:57.274+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:22:57.281+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:22:57.306+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.131 seconds
[2022-11-21T21:23:27.449+0000] {processor.py:154} INFO - Started process (PID=21004) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:23:27.460+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:23:27.463+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:23:27.463+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:23:27.553+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:23:27.546+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    filename = "1.csv")
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:23:27.557+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:23:27.582+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.139 seconds
[2022-11-21T21:23:44.854+0000] {processor.py:154} INFO - Started process (PID=21024) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:23:44.866+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:23:44.869+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:23:44.869+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:23:45.045+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:23:45.033+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    sql = '''select * from countries''',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:23:45.053+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:23:45.164+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.314 seconds
[2022-11-21T21:24:15.448+0000] {processor.py:154} INFO - Started process (PID=21048) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:24:15.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:24:15.453+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:24:15.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:24:15.527+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:24:15.521+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    sql = '''select * from countries''',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:24:15.530+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:24:15.554+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.110 seconds
[2022-11-21T21:24:46.245+0000] {processor.py:154} INFO - Started process (PID=21079) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:24:46.252+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:24:46.254+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:24:46.254+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:24:46.339+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:24:46.334+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 29, in <module>
    sql = '''select * from countries''',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/opt/airflow/plugins/operators/pgtos3.py", line 10, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 408, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2022-11-21T21:24:46.346+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:24:46.366+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.126 seconds
[2022-11-21T21:25:05.235+0000] {processor.py:154} INFO - Started process (PID=21103) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:05.239+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:25:05.243+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:05.243+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:05.290+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:05.288+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 20
    database = "aws",
           ^
SyntaxError: invalid syntax
[2022-11-21T21:25:05.292+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:05.340+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.111 seconds
[2022-11-21T21:25:26.868+0000] {processor.py:154} INFO - Started process (PID=21125) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:26.871+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:25:26.874+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:26.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:27.016+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:27.092+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:27.092+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:25:27.125+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:27.125+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:25:27.154+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.290 seconds
[2022-11-21T21:25:57.320+0000] {processor.py:154} INFO - Started process (PID=21149) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:57.323+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:25:57.325+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:57.324+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:57.386+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:57.429+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:57.429+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:25:57.448+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:57.448+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:25:57.461+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.145 seconds
[2022-11-21T21:25:58.372+0000] {processor.py:154} INFO - Started process (PID=21159) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:58.376+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:25:58.379+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:58.379+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:58.589+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:25:58.779+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:58.779+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:25:58.831+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:25:58.831+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:25:58.875+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.509 seconds
[2022-11-21T21:26:29.097+0000] {processor.py:154} INFO - Started process (PID=21183) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:26:29.101+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:26:29.104+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:26:29.104+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:26:29.186+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:26:29.224+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:26:29.224+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:26:29.247+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:26:29.247+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:26:29.259+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.167 seconds
[2022-11-21T21:26:59.544+0000] {processor.py:154} INFO - Started process (PID=21216) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:26:59.559+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:26:59.574+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:26:59.574+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:26:59.808+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:26:59.916+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:26:59.915+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:27:00.132+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:27:00.128+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:27:00.296+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.776 seconds
[2022-11-21T21:27:31.341+0000] {processor.py:154} INFO - Started process (PID=21250) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:27:31.346+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:27:31.352+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:27:31.351+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:27:31.426+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:27:31.467+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:27:31.467+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:27:31.488+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:27:31.487+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:27:31.500+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.167 seconds
[2022-11-21T21:28:01.710+0000] {processor.py:154} INFO - Started process (PID=21274) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:28:01.714+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:28:01.717+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:28:01.716+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:28:01.789+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:28:01.831+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:28:01.831+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:28:01.853+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:28:01.852+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:28:01.880+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.175 seconds
[2022-11-21T21:28:32.400+0000] {processor.py:154} INFO - Started process (PID=21308) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:28:32.404+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:28:32.408+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:28:32.408+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:28:32.584+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:28:32.621+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:28:32.621+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:28:32.642+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:28:32.642+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:28:32.655+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.260 seconds
[2022-11-21T21:29:02.740+0000] {processor.py:154} INFO - Started process (PID=21341) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:29:02.742+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:29:02.744+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:29:02.744+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:29:02.811+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:29:02.850+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:29:02.849+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:29:02.867+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:29:02.867+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:29:02.879+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.142 seconds
[2022-11-21T21:29:33.035+0000] {processor.py:154} INFO - Started process (PID=21364) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:29:33.038+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:29:33.040+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:29:33.040+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:29:33.114+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:29:33.151+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:29:33.151+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:29:33.169+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:29:33.169+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:29:33.180+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.149 seconds
[2022-11-21T21:30:03.839+0000] {processor.py:154} INFO - Started process (PID=21396) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:30:03.843+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:30:03.846+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:30:03.846+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:30:03.912+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:30:03.948+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:30:03.948+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:30:03.967+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:30:03.967+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:30:03.979+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.145 seconds
[2022-11-21T21:30:34.079+0000] {processor.py:154} INFO - Started process (PID=21428) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:30:34.083+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:30:34.086+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:30:34.086+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:30:34.167+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:30:34.161+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:30:34.171+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:30:34.198+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.125 seconds
[2022-11-21T21:31:04.834+0000] {processor.py:154} INFO - Started process (PID=21461) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:31:04.840+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:31:04.847+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:31:04.847+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:31:04.945+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:31:04.935+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:31:04.953+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:31:05.001+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.172 seconds
[2022-11-21T21:31:35.588+0000] {processor.py:154} INFO - Started process (PID=21484) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:31:35.594+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:31:35.596+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:31:35.596+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:31:35.675+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:31:35.663+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:31:35.679+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:31:35.737+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.154 seconds
[2022-11-21T21:32:06.284+0000] {processor.py:154} INFO - Started process (PID=21516) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:32:06.285+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:32:06.287+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:32:06.287+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:32:06.349+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:32:06.344+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:32:06.352+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:32:06.372+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.093 seconds
[2022-11-21T21:32:36.475+0000] {processor.py:154} INFO - Started process (PID=21550) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:32:36.479+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:32:36.485+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:32:36.485+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:32:36.520+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:32:36.518+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    conn.commit()
    ^
IndentationError: unexpected indent
[2022-11-21T21:32:36.521+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:32:36.541+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.073 seconds
[2022-11-21T21:33:06.629+0000] {processor.py:154} INFO - Started process (PID=21572) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:33:06.631+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:33:06.632+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:33:06.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:33:06.671+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:33:06.668+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    conn.commit()
    ^
IndentationError: unexpected indent
[2022-11-21T21:33:06.673+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:33:06.691+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.065 seconds
[2022-11-21T21:33:37.328+0000] {processor.py:154} INFO - Started process (PID=21601) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:33:37.331+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:33:37.332+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:33:37.332+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:33:37.389+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:33:37.387+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 50
    return s3
    ^
SyntaxError: 'return' outside function
[2022-11-21T21:33:37.391+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:33:37.447+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.125 seconds
[2022-11-21T21:34:07.941+0000] {processor.py:154} INFO - Started process (PID=21634) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:34:07.945+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:34:07.949+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:34:07.949+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:34:08.054+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:34:08.028+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:34:08.058+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:34:08.140+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.204 seconds
[2022-11-21T21:34:38.267+0000] {processor.py:154} INFO - Started process (PID=21668) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:34:38.271+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:34:38.275+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:34:38.274+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:34:38.431+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:34:38.420+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:34:38.435+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:34:38.473+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.211 seconds
[2022-11-21T21:35:08.956+0000] {processor.py:154} INFO - Started process (PID=21692) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:35:08.960+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:35:08.966+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:35:08.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:35:09.029+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:35:09.023+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:35:09.031+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:35:09.052+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.101 seconds
[2022-11-21T21:35:39.258+0000] {processor.py:154} INFO - Started process (PID=21725) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:35:39.260+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:35:39.262+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:35:39.262+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:35:39.327+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:35:39.322+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:35:39.328+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:35:39.350+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.095 seconds
[2022-11-21T21:36:09.983+0000] {processor.py:154} INFO - Started process (PID=21758) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:36:09.985+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:36:09.987+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:36:09.987+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:36:10.043+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:36:10.038+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:36:10.045+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:36:10.064+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.084 seconds
[2022-11-21T21:36:40.622+0000] {processor.py:154} INFO - Started process (PID=21782) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:36:40.626+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:36:40.629+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:36:40.629+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:36:40.728+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:36:40.724+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:36:40.731+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:36:40.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.159 seconds
[2022-11-21T21:37:11.306+0000] {processor.py:154} INFO - Started process (PID=21816) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:37:11.308+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:37:11.310+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:37:11.310+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:37:11.413+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:37:11.403+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:37:11.416+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:37:11.452+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.150 seconds
[2022-11-21T21:37:42.013+0000] {processor.py:154} INFO - Started process (PID=21848) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:37:42.016+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:37:42.019+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:37:42.019+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:37:42.081+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:37:42.076+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:37:42.082+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:37:42.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.094 seconds
[2022-11-21T21:38:12.907+0000] {processor.py:154} INFO - Started process (PID=21880) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:38:12.913+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:38:12.916+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:38:12.916+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:38:12.983+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:38:12.978+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 23, in PostgresToS3Operator
    s3 = s3()
NameError: name 's3' is not defined
[2022-11-21T21:38:12.990+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:38:13.009+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.106 seconds
[2022-11-21T21:38:43.478+0000] {processor.py:154} INFO - Started process (PID=21903) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:38:43.500+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:38:43.507+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:38:43.507+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:38:43.780+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:38:43.742+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:38:43.795+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:38:43.897+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.434 seconds
[2022-11-21T21:39:14.358+0000] {processor.py:154} INFO - Started process (PID=21936) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:39:14.363+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:39:14.365+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:39:14.365+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:39:14.446+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:39:14.440+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:39:14.448+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:39:14.472+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.121 seconds
[2022-11-21T21:39:45.275+0000] {processor.py:154} INFO - Started process (PID=21969) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:39:45.280+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:39:45.287+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:39:45.286+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:39:45.369+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:39:45.363+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(self)
NameError: name 'self' is not defined
[2022-11-21T21:39:45.371+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:39:45.389+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.118 seconds
[2022-11-21T21:40:15.627+0000] {processor.py:154} INFO - Started process (PID=21992) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:40:15.630+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:40:15.632+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:40:15.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:40:15.725+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:40:15.702+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(self)
NameError: name 'self' is not defined
[2022-11-21T21:40:15.729+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:40:15.767+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.144 seconds
[2022-11-21T21:40:45.949+0000] {processor.py:154} INFO - Started process (PID=22025) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:40:45.951+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:40:45.952+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:40:45.952+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:40:46.029+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:40:46.024+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:40:46.046+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:40:46.071+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.126 seconds
[2022-11-21T21:41:16.227+0000] {processor.py:154} INFO - Started process (PID=22059) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:41:16.236+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:41:16.243+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:41:16.242+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:41:16.474+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:41:16.468+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:41:16.476+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:41:16.524+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.306 seconds
[2022-11-21T21:41:46.602+0000] {processor.py:154} INFO - Started process (PID=22085) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:41:46.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:41:46.607+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:41:46.607+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:41:46.688+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:41:46.682+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:41:46.691+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:41:46.717+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.120 seconds
[2022-11-21T21:42:16.883+0000] {processor.py:154} INFO - Started process (PID=22117) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:42:16.887+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:42:16.889+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:42:16.889+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:42:16.956+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:42:16.951+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:42:16.959+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:42:16.982+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.105 seconds
[2022-11-21T21:42:47.576+0000] {processor.py:154} INFO - Started process (PID=22150) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:42:47.580+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:42:47.582+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:42:47.582+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:42:47.656+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:42:47.650+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:42:47.658+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:42:47.678+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.108 seconds
[2022-11-21T21:43:18.427+0000] {processor.py:154} INFO - Started process (PID=22184) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:43:18.428+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:43:18.430+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:43:18.430+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:43:18.524+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:43:18.576+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:43:18.576+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:43:18.591+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:43:18.591+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:43:18.604+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.183 seconds
[2022-11-21T21:43:48.787+0000] {processor.py:154} INFO - Started process (PID=22208) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:43:48.790+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:43:48.792+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:43:48.792+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:43:48.879+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:43:48.913+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:43:48.913+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:43:48.930+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:43:48.930+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:43:48.947+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.165 seconds
[2022-11-21T21:44:19.165+0000] {processor.py:154} INFO - Started process (PID=22241) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:44:19.168+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:44:19.171+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:44:19.171+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:44:19.252+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:44:19.282+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:44:19.282+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:44:19.298+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:44:19.298+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:44:19.310+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.151 seconds
[2022-11-21T21:44:49.437+0000] {processor.py:154} INFO - Started process (PID=22274) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:44:49.439+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:44:49.440+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:44:49.440+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:44:49.510+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:44:49.548+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:44:49.548+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:44:49.564+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:44:49.564+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:44:49.577+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.143 seconds
[2022-11-21T21:45:20.102+0000] {processor.py:154} INFO - Started process (PID=22307) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:45:20.107+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:45:20.109+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:45:20.108+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:45:20.214+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:45:20.252+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:45:20.252+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:45:20.276+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:45:20.276+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:45:20.291+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.195 seconds
[2022-11-21T21:45:50.583+0000] {processor.py:154} INFO - Started process (PID=22330) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:45:50.586+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:45:50.588+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:45:50.588+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:45:50.656+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:45:50.689+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:45:50.688+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:45:50.711+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:45:50.711+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:45:50.735+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.156 seconds
[2022-11-21T21:46:21.340+0000] {processor.py:154} INFO - Started process (PID=22362) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:46:21.344+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:46:21.346+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:46:21.346+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:46:21.491+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:46:21.483+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 4 required positional arguments: 'self', 'region_name', 'access_key', and 'secret_access_key'
[2022-11-21T21:46:21.498+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:46:21.539+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.206 seconds
[2022-11-21T21:46:52.005+0000] {processor.py:154} INFO - Started process (PID=22395) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:46:52.007+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:46:52.009+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:46:52.009+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:46:52.097+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:46:52.091+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 4 required positional arguments: 'self', 'region_name', 'access_key', and 'secret_access_key'
[2022-11-21T21:46:52.099+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:46:52.127+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.126 seconds
[2022-11-21T21:47:22.710+0000] {processor.py:154} INFO - Started process (PID=22428) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:47:22.718+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:47:22.729+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:47:22.729+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:47:23.180+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:47:23.146+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:47:23.205+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:47:23.298+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.601 seconds
[2022-11-21T21:47:53.447+0000] {processor.py:154} INFO - Started process (PID=22451) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:47:53.451+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:47:53.453+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:47:53.453+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:47:53.522+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:47:53.516+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:47:53.524+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:47:53.544+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.101 seconds
[2022-11-21T21:48:24.010+0000] {processor.py:154} INFO - Started process (PID=22483) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:48:24.012+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:48:24.014+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:48:24.014+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:48:24.099+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:48:24.091+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:48:24.101+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:48:24.147+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.142 seconds
[2022-11-21T21:48:54.283+0000] {processor.py:154} INFO - Started process (PID=22517) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:48:54.287+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:48:54.290+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:48:54.290+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:48:54.352+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:48:54.347+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:48:54.354+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:48:54.377+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.099 seconds
[2022-11-21T21:49:24.841+0000] {processor.py:154} INFO - Started process (PID=22548) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:49:24.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:49:24.846+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:49:24.845+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:49:24.952+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:49:24.943+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:49:24.956+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:49:24.984+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.146 seconds
[2022-11-21T21:49:55.416+0000] {processor.py:154} INFO - Started process (PID=22574) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:49:55.418+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:49:55.423+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:49:55.423+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:49:55.481+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:49:55.477+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:49:55.484+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:49:55.504+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.092 seconds
[2022-11-21T21:50:25.677+0000] {processor.py:154} INFO - Started process (PID=22606) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:50:25.679+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:50:25.681+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:50:25.681+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:50:25.756+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:50:25.752+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:50:25.758+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:50:25.776+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.103 seconds
[2022-11-21T21:50:56.010+0000] {processor.py:154} INFO - Started process (PID=22639) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:50:56.014+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:50:56.016+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:50:56.016+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:50:56.091+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:50:56.087+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:50:56.093+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:50:56.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.109 seconds
[2022-11-21T21:51:26.271+0000] {processor.py:154} INFO - Started process (PID=22663) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:51:26.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:51:26.275+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:51:26.275+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:51:26.340+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:51:26.335+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:51:26.342+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:51:26.363+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.096 seconds
[2022-11-21T21:51:56.719+0000] {processor.py:154} INFO - Started process (PID=22694) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:51:56.723+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:51:56.725+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:51:56.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:51:56.789+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:51:56.784+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:51:56.790+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:51:56.812+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.097 seconds
[2022-11-21T21:52:27.463+0000] {processor.py:154} INFO - Started process (PID=22727) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:52:27.467+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:52:27.470+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:52:27.470+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:52:27.547+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:52:27.543+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(region_name, access_key, secret_access_key)
NameError: name 'region_name' is not defined
[2022-11-21T21:52:27.549+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:52:27.569+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.113 seconds
[2022-11-21T21:52:57.643+0000] {processor.py:154} INFO - Started process (PID=22761) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:52:57.650+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:52:57.652+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:52:57.652+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:52:57.765+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:52:57.760+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T21:52:57.768+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:52:57.791+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.152 seconds
[2022-11-21T21:53:28.019+0000] {processor.py:154} INFO - Started process (PID=22785) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:53:28.026+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:53:28.032+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:53:28.031+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:53:28.222+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:53:28.318+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:53:28.318+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:53:28.423+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:53:28.423+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:53:28.574+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.564 seconds
[2022-11-21T21:53:58.842+0000] {processor.py:154} INFO - Started process (PID=22818) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:53:58.846+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:53:58.848+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:53:58.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:53:58.980+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:53:59.020+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:53:59.020+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:53:59.039+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:53:59.039+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:53:59.052+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.217 seconds
[2022-11-21T21:54:29.634+0000] {processor.py:154} INFO - Started process (PID=22851) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:54:29.638+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:54:29.640+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:54:29.640+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:54:29.774+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:54:29.827+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:54:29.826+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:54:29.871+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:54:29.871+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:54:29.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.267 seconds
[2022-11-21T21:54:59.964+0000] {processor.py:154} INFO - Started process (PID=22883) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:54:59.967+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:54:59.969+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:54:59.969+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:55:00.062+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:55:00.104+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:55:00.103+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T21:55:00.129+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:55:00.129+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T21:55:00.151+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.191 seconds
[2022-11-21T21:55:30.409+0000] {processor.py:154} INFO - Started process (PID=22905) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:55:30.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:55:30.414+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:55:30.413+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:55:30.498+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:55:30.493+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(self)
NameError: name 'self' is not defined
[2022-11-21T21:55:30.499+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:55:30.532+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.130 seconds
[2022-11-21T21:56:00.637+0000] {processor.py:154} INFO - Started process (PID=22938) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:56:00.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:56:00.642+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:56:00.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:56:00.727+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:56:00.717+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(self)
NameError: name 'self' is not defined
[2022-11-21T21:56:00.729+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:56:00.757+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.125 seconds
[2022-11-21T21:56:30.840+0000] {processor.py:154} INFO - Started process (PID=22972) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:56:30.845+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:56:30.847+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:56:30.847+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:56:30.942+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:56:30.937+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 49, in PostgresToS3Operator
    s3 = s3(self)
NameError: name 'self' is not defined
[2022-11-21T21:56:30.945+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:56:30.973+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.137 seconds
[2022-11-21T21:57:01.259+0000] {processor.py:154} INFO - Started process (PID=22996) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:57:01.263+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:57:01.265+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:57:01.265+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:57:01.386+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:57:01.381+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 43, in PostgresToS3Operator
    region_name=self.region_name,
NameError: name 'self' is not defined
[2022-11-21T21:57:01.391+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:57:01.424+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.175 seconds
[2022-11-21T21:57:31.629+0000] {processor.py:154} INFO - Started process (PID=23031) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:57:31.631+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:57:31.632+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:57:31.632+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:57:31.705+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:57:31.700+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 43, in PostgresToS3Operator
    region_name=self.region_name,
NameError: name 'self' is not defined
[2022-11-21T21:57:31.707+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:57:31.728+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.103 seconds
[2022-11-21T21:58:02.089+0000] {processor.py:154} INFO - Started process (PID=23063) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:58:02.093+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:58:02.095+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:58:02.095+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:58:02.183+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:58:02.178+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 43, in PostgresToS3Operator
    region_name=self.region_name,
NameError: name 'self' is not defined
[2022-11-21T21:58:02.186+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:58:02.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.138 seconds
[2022-11-21T21:58:32.437+0000] {processor.py:154} INFO - Started process (PID=23087) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:58:32.440+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:58:32.442+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:58:32.442+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:58:32.637+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:58:32.630+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 43, in PostgresToS3Operator
    region_name=region_name,
NameError: name 'region_name' is not defined
[2022-11-21T21:58:32.641+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:58:32.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.313 seconds
[2022-11-21T21:59:02.960+0000] {processor.py:154} INFO - Started process (PID=23119) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:59:02.965+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:59:02.967+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:59:02.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:59:03.086+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:59:03.080+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 43, in PostgresToS3Operator
    region_name=region_name,
NameError: name 'region_name' is not defined
[2022-11-21T21:59:03.087+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:59:03.112+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.160 seconds
[2022-11-21T21:59:33.243+0000] {processor.py:154} INFO - Started process (PID=23152) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:59:33.250+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T21:59:33.251+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:59:33.251+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:59:33.323+0000] {logging_mixin.py:120} INFO - [2022-11-21T21:59:33.319+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 43, in PostgresToS3Operator
    region_name=region_name,
NameError: name 'region_name' is not defined
[2022-11-21T21:59:33.325+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T21:59:33.346+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.107 seconds
[2022-11-21T22:00:04.073+0000] {processor.py:154} INFO - Started process (PID=23174) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:00:04.082+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:00:04.090+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:00:04.089+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:00:04.259+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:00:04.252+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 6, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 43, in PostgresToS3Operator
    region_name=region_name,
NameError: name 'region_name' is not defined
[2022-11-21T22:00:04.262+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:00:04.327+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.277 seconds
[2022-11-21T22:00:34.598+0000] {processor.py:154} INFO - Started process (PID=23207) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:00:34.605+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:00:34.617+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:00:34.617+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:00:34.959+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:00:35.121+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:00:35.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:00:35.160+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:00:35.160+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:00:35.197+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.621 seconds
[2022-11-21T22:01:06.239+0000] {processor.py:154} INFO - Started process (PID=23239) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:01:06.247+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:01:06.250+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:01:06.250+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:01:06.361+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:01:06.414+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:01:06.414+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:01:06.439+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:01:06.439+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:01:06.454+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.230 seconds
[2022-11-21T22:01:36.644+0000] {processor.py:154} INFO - Started process (PID=23271) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:01:36.650+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:01:36.654+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:01:36.654+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:01:36.765+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:01:36.815+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:01:36.815+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:01:36.846+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:01:36.845+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:01:36.864+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.228 seconds
[2022-11-21T22:02:07.906+0000] {processor.py:154} INFO - Started process (PID=23295) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:02:07.915+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:02:07.917+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:02:07.917+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:02:08.075+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:02:08.165+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:02:08.165+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:02:08.196+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:02:08.196+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:02:08.211+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.316 seconds
[2022-11-21T22:02:39.028+0000] {processor.py:154} INFO - Started process (PID=23328) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:02:39.034+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:02:39.037+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:02:39.037+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:02:39.148+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:02:39.186+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:02:39.186+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:02:39.207+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:02:39.207+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:02:39.222+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.200 seconds
[2022-11-21T22:03:09.680+0000] {processor.py:154} INFO - Started process (PID=23360) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:03:09.684+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:03:09.688+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:03:09.688+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:03:09.826+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:03:09.875+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:03:09.874+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:03:09.900+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:03:09.900+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:03:09.915+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.247 seconds
[2022-11-21T22:03:40.742+0000] {processor.py:154} INFO - Started process (PID=23393) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:03:40.750+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:03:40.757+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:03:40.757+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:03:40.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:03:41.069+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:03:41.069+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:03:41.141+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:03:41.140+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:03:41.179+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.447 seconds
[2022-11-21T22:04:12.249+0000] {processor.py:154} INFO - Started process (PID=23417) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:04:12.254+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:04:12.256+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:04:12.256+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:04:12.436+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:04:12.581+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:04:12.581+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:04:12.649+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:04:12.649+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:04:12.690+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.447 seconds
[2022-11-21T22:04:43.635+0000] {processor.py:154} INFO - Started process (PID=23450) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:04:43.639+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:04:43.641+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:04:43.640+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:04:43.902+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:04:43.954+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:04:43.954+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:04:43.980+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:04:43.980+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:04:43.998+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.369 seconds
[2022-11-21T22:05:15.071+0000] {processor.py:154} INFO - Started process (PID=23483) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:05:15.075+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:05:15.076+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:05:15.076+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:05:15.184+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:05:15.234+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:05:15.234+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:05:15.259+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:05:15.259+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:05:15.275+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.209 seconds
[2022-11-21T22:05:46.243+0000] {processor.py:154} INFO - Started process (PID=23516) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:05:46.259+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:05:46.281+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:05:46.280+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:05:46.914+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:05:46.896+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 50, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T22:05:46.926+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:05:47.135+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.928 seconds
[2022-11-21T22:06:17.611+0000] {processor.py:154} INFO - Started process (PID=23540) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:06:17.614+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:06:17.617+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:06:17.616+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:06:17.729+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:06:17.720+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 50, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T22:06:17.755+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:06:17.777+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.172 seconds
[2022-11-21T22:06:47.999+0000] {processor.py:154} INFO - Started process (PID=23572) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:06:48.003+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:06:48.005+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:06:48.005+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:06:48.105+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:06:48.097+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 7, in <module>
    class PostgresToS3Operator(BaseOperator):
  File "/opt/airflow/plugins/operators/pgtos3.py", line 50, in PostgresToS3Operator
    s3 = s3()
TypeError: s3() missing 1 required positional argument: 'self'
[2022-11-21T22:06:48.107+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:06:48.133+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.139 seconds
[2022-11-21T22:07:18.808+0000] {processor.py:154} INFO - Started process (PID=23603) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:07:18.819+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:07:18.826+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:07:18.825+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:07:19.104+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:07:19.291+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:07:19.291+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:07:19.324+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:07:19.323+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:07:19.343+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.541 seconds
[2022-11-21T22:07:49.640+0000] {processor.py:154} INFO - Started process (PID=23627) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:07:49.644+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:07:49.646+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:07:49.645+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:07:49.756+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:07:49.793+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:07:49.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:07:49.819+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:07:49.818+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:07:49.832+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.198 seconds
[2022-11-21T22:08:20.126+0000] {processor.py:154} INFO - Started process (PID=23658) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:08:20.129+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:08:20.131+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:08:20.131+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:08:20.241+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:08:20.280+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:08:20.280+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:08:20.301+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:08:20.301+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:08:20.313+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.192 seconds
[2022-11-21T22:08:50.880+0000] {processor.py:154} INFO - Started process (PID=23692) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:08:50.886+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:08:50.892+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:08:50.892+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:08:51.017+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:08:51.058+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:08:51.058+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:08:51.085+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:08:51.085+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:08:51.102+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.231 seconds
[2022-11-21T22:09:21.780+0000] {processor.py:154} INFO - Started process (PID=23716) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:09:21.784+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:09:21.787+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:09:21.787+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:09:21.953+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:09:22.000+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:09:22.000+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:09:22.033+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:09:22.032+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:09:22.044+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.272 seconds
[2022-11-21T22:09:52.342+0000] {processor.py:154} INFO - Started process (PID=23748) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:09:52.345+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:09:52.347+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:09:52.347+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:09:52.435+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:09:52.477+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:09:52.477+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:09:52.506+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:09:52.506+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:09:52.525+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.194 seconds
[2022-11-21T22:10:22.694+0000] {processor.py:154} INFO - Started process (PID=23782) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:10:22.698+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:10:22.700+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:10:22.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:10:22.792+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:10:22.830+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:10:22.830+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:10:22.866+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:10:22.866+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:10:22.878+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.190 seconds
[2022-11-21T22:10:53.121+0000] {processor.py:154} INFO - Started process (PID=23806) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:10:53.126+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:10:53.128+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:10:53.128+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:10:53.254+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:10:53.309+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:10:53.309+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:10:53.337+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:10:53.337+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:10:53.353+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.237 seconds
[2022-11-21T22:11:23.509+0000] {processor.py:154} INFO - Started process (PID=23837) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:11:23.514+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:11:23.517+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:11:23.517+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:11:23.719+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:11:23.802+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:11:23.802+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:11:23.840+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:11:23.840+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:11:23.863+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.362 seconds
[2022-11-21T22:11:53.981+0000] {processor.py:154} INFO - Started process (PID=23870) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:11:53.983+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:11:53.985+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:11:53.984+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:11:54.074+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:11:54.113+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:11:54.112+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:11:54.140+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:11:54.139+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:11:54.155+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.180 seconds
[2022-11-21T22:12:24.821+0000] {processor.py:154} INFO - Started process (PID=23903) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:12:24.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:12:24.826+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:12:24.826+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:12:24.907+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:12:24.941+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:12:24.941+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:12:24.964+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:12:24.964+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:12:24.978+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.164 seconds
[2022-11-21T22:12:55.221+0000] {processor.py:154} INFO - Started process (PID=23926) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:12:55.224+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:12:55.226+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:12:55.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:12:55.321+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:12:55.364+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:12:55.364+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:12:55.387+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:12:55.387+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:12:55.400+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.183 seconds
[2022-11-21T22:13:25.691+0000] {processor.py:154} INFO - Started process (PID=23961) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:13:25.694+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:13:25.695+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:13:25.695+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:13:25.844+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:13:25.895+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:13:25.895+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:13:25.914+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:13:25.913+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:13:25.925+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.237 seconds
[2022-11-21T22:13:56.261+0000] {processor.py:154} INFO - Started process (PID=23995) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:13:56.266+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:13:56.268+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:13:56.268+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:13:56.358+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:13:56.395+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:13:56.395+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:13:56.417+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:13:56.417+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:13:56.430+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.174 seconds
[2022-11-21T22:14:27.019+0000] {processor.py:154} INFO - Started process (PID=24028) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:14:27.026+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:14:27.028+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:14:27.028+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:14:27.162+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:14:27.233+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:14:27.232+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:14:27.324+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:14:27.323+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:14:27.342+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.328 seconds
[2022-11-21T22:14:57.893+0000] {processor.py:154} INFO - Started process (PID=24052) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:14:57.901+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:14:57.904+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:14:57.904+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:14:58.031+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:14:58.085+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:14:58.085+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:14:58.112+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:14:58.111+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:14:58.134+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.249 seconds
[2022-11-21T22:15:28.322+0000] {processor.py:154} INFO - Started process (PID=24087) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:15:28.324+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:15:28.326+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:15:28.325+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:15:28.392+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:15:28.421+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:15:28.421+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:15:28.438+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:15:28.438+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:15:28.449+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.130 seconds
[2022-11-21T22:15:58.765+0000] {processor.py:154} INFO - Started process (PID=24118) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:15:58.767+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:15:58.769+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:15:58.769+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:15:58.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:15:58.928+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:15:58.928+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:15:58.954+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:15:58.954+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:15:58.966+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.206 seconds
[2022-11-21T22:16:29.224+0000] {processor.py:154} INFO - Started process (PID=24152) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:16:29.245+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:16:29.260+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:16:29.260+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:16:29.435+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:16:29.493+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:16:29.492+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:16:29.528+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:16:29.528+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:16:29.551+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.364 seconds
[2022-11-21T22:17:00.012+0000] {processor.py:154} INFO - Started process (PID=24174) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:17:00.015+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:17:00.017+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:17:00.017+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:17:00.110+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:17:00.143+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:17:00.143+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:17:00.163+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:17:00.163+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:17:00.175+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.168 seconds
[2022-11-21T22:17:30.912+0000] {processor.py:154} INFO - Started process (PID=24205) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:17:30.914+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:17:30.921+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:17:30.921+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:17:31.047+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:17:31.089+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:17:31.089+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:17:31.109+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:17:31.109+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:17:31.122+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.216 seconds
[2022-11-21T22:18:01.260+0000] {processor.py:154} INFO - Started process (PID=24238) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:18:01.266+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:18:01.274+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:18:01.273+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:18:01.501+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:18:01.546+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:18:01.546+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:18:01.572+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:18:01.571+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:18:01.584+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.339 seconds
[2022-11-21T22:18:31.899+0000] {processor.py:154} INFO - Started process (PID=24262) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:18:31.903+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:18:31.905+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:18:31.904+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:18:32.032+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:18:32.072+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:18:32.071+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:18:32.095+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:18:32.095+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:18:32.109+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.217 seconds
[2022-11-21T22:19:02.479+0000] {processor.py:154} INFO - Started process (PID=24295) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:19:02.481+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:19:02.484+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:19:02.484+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:19:02.580+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:19:02.621+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:19:02.621+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:19:02.643+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:19:02.643+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:19:02.656+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.183 seconds
[2022-11-21T22:19:33.269+0000] {processor.py:154} INFO - Started process (PID=24327) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:19:33.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:19:33.278+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:19:33.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:19:33.471+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:19:33.570+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:19:33.570+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:19:33.615+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:19:33.614+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:19:33.647+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.384 seconds
[2022-11-21T22:20:04.018+0000] {processor.py:154} INFO - Started process (PID=24351) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:20:04.021+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:20:04.023+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:20:04.023+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:20:04.147+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:20:04.201+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:20:04.201+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:20:04.220+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:20:04.219+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:20:04.230+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.221 seconds
[2022-11-21T22:20:34.484+0000] {processor.py:154} INFO - Started process (PID=24384) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:20:34.490+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:20:34.493+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:20:34.493+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:20:34.609+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:20:34.653+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:20:34.653+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:20:34.677+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:20:34.677+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:20:34.690+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.218 seconds
[2022-11-21T22:21:05.190+0000] {processor.py:154} INFO - Started process (PID=24416) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:21:05.198+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:21:05.205+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:21:05.205+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:21:05.331+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:21:05.325+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    def postgres(self):
      ^
IndentationError: expected an indented block
[2022-11-21T22:21:05.342+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:21:05.461+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.281 seconds
[2022-11-21T22:21:35.666+0000] {processor.py:154} INFO - Started process (PID=24442) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:21:35.670+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:21:35.672+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:21:35.672+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:21:35.720+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:21:35.716+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    def postgres(self):
      ^
IndentationError: expected an indented block
[2022-11-21T22:21:35.722+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:21:35.752+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.092 seconds
[2022-11-21T22:22:06.089+0000] {processor.py:154} INFO - Started process (PID=24476) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:22:06.092+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:22:06.094+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:22:06.093+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:22:06.144+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:22:06.140+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    def postgres(self):
      ^
IndentationError: expected an indented block
[2022-11-21T22:22:06.150+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:22:06.176+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.092 seconds
[2022-11-21T22:22:36.667+0000] {processor.py:154} INFO - Started process (PID=24509) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:22:36.681+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:22:36.700+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:22:36.700+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:22:36.787+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:22:36.776+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    def postgres(self):
      ^
IndentationError: expected an indented block
[2022-11-21T22:22:36.792+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:22:36.873+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.224 seconds
[2022-11-21T22:23:07.368+0000] {processor.py:154} INFO - Started process (PID=24534) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:23:07.371+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:23:07.373+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:23:07.373+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:23:07.427+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:23:07.423+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    def postgres(self):
      ^
IndentationError: expected an indented block
[2022-11-21T22:23:07.428+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:23:07.456+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.094 seconds
[2022-11-21T22:23:37.754+0000] {processor.py:154} INFO - Started process (PID=24558) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:23:37.763+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:23:37.767+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:23:37.767+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:23:37.821+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:23:37.818+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 29
    def postgres(self):
      ^
IndentationError: expected an indented block
[2022-11-21T22:23:37.826+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:23:37.893+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.151 seconds
[2022-11-21T22:24:08.638+0000] {processor.py:154} INFO - Started process (PID=24591) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:24:08.646+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:24:08.654+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:24:08.654+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:24:09.063+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:24:09.161+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:24:09.161+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:24:09.182+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:24:09.182+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:24:09.200+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.603 seconds
[2022-11-21T22:24:39.452+0000] {processor.py:154} INFO - Started process (PID=24623) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:24:39.455+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:24:39.457+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:24:39.457+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:24:39.601+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:24:39.654+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:24:39.654+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:24:39.680+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:24:39.680+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:24:39.696+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.252 seconds
[2022-11-21T22:25:09.867+0000] {processor.py:154} INFO - Started process (PID=24656) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:25:09.871+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:25:09.874+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:25:09.874+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:25:10.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:25:10.103+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:25:10.102+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:25:10.131+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:25:10.131+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:25:10.153+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.290 seconds
[2022-11-21T22:25:40.392+0000] {processor.py:154} INFO - Started process (PID=24679) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:25:40.395+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:25:40.397+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:25:40.397+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:25:40.550+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:25:40.600+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:25:40.600+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:25:40.621+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:25:40.621+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:25:40.635+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.251 seconds
[2022-11-21T22:26:11.014+0000] {processor.py:154} INFO - Started process (PID=24711) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:26:11.017+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:26:11.020+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:26:11.019+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:26:11.128+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:26:11.176+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:26:11.176+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:26:11.198+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:26:11.198+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:26:11.211+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.203 seconds
[2022-11-21T22:26:41.389+0000] {processor.py:154} INFO - Started process (PID=24744) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:26:41.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:26:41.394+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:26:41.394+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:26:41.476+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:26:41.513+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:26:41.513+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:26:41.536+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:26:41.536+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:26:41.552+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.168 seconds
[2022-11-21T22:27:11.995+0000] {processor.py:154} INFO - Started process (PID=24769) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:27:12.003+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:27:12.005+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:27:12.005+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:27:12.081+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:27:12.117+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:27:12.117+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:27:12.138+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:27:12.138+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:27:12.154+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.165 seconds
[2022-11-21T22:27:42.241+0000] {processor.py:154} INFO - Started process (PID=24801) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:27:42.244+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:27:42.245+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:27:42.245+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:27:42.356+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:27:42.402+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:27:42.402+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:27:42.419+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:27:42.419+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:27:42.432+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.194 seconds
[2022-11-21T22:28:13.105+0000] {processor.py:154} INFO - Started process (PID=24832) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:28:13.111+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:28:13.116+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:28:13.116+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:28:13.255+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:28:13.248+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 26
    print self.postgres
             ^
SyntaxError: Missing parentheses in call to 'print'. Did you mean print(self.postgres)?
[2022-11-21T22:28:13.260+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:28:13.366+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.303 seconds
[2022-11-21T22:28:44.343+0000] {processor.py:154} INFO - Started process (PID=24865) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:28:44.346+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:28:44.351+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:28:44.351+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:28:44.427+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:28:44.421+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 26
    print self.postgres
             ^
SyntaxError: Missing parentheses in call to 'print'. Did you mean print(self.postgres)?
[2022-11-21T22:28:44.431+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:28:44.468+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.131 seconds
[2022-11-21T22:29:15.556+0000] {processor.py:154} INFO - Started process (PID=24890) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:29:15.561+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:29:15.563+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:29:15.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:29:15.717+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:29:15.838+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:29:15.838+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:29:15.873+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:29:15.873+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:29:15.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.349 seconds
[2022-11-21T22:29:46.751+0000] {processor.py:154} INFO - Started process (PID=24922) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:29:46.765+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:29:46.768+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:29:46.768+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:29:46.852+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:29:46.907+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:29:46.907+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:29:46.928+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:29:46.928+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:29:46.943+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.197 seconds
[2022-11-21T22:30:17.218+0000] {processor.py:154} INFO - Started process (PID=24955) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:30:17.222+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:30:17.225+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:30:17.225+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:30:17.343+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:30:17.382+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:30:17.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:30:17.406+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:30:17.405+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:30:17.420+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.207 seconds
[2022-11-21T22:30:47.665+0000] {processor.py:154} INFO - Started process (PID=24979) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:30:47.697+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:30:47.701+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:30:47.701+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:30:47.925+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:30:48.040+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:30:48.039+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:30:48.110+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:30:48.110+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:30:48.153+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.500 seconds
[2022-11-21T22:31:18.384+0000] {processor.py:154} INFO - Started process (PID=25011) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:31:18.387+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:31:18.388+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:31:18.388+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:31:18.867+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:31:18.897+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:31:18.897+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:31:18.913+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:31:18.913+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:31:18.928+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.550 seconds
[2022-11-21T22:31:49.484+0000] {processor.py:154} INFO - Started process (PID=25046) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:31:49.487+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:31:49.488+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:31:49.488+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:31:49.778+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:31:49.803+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:31:49.803+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:31:49.818+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:31:49.818+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:31:49.828+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.348 seconds
[2022-11-21T22:32:20.379+0000] {processor.py:154} INFO - Started process (PID=25079) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:32:20.384+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:32:20.387+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:32:20.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:32:20.767+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:32:20.837+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:32:20.836+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:32:20.857+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:32:20.857+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:32:20.871+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.500 seconds
[2022-11-21T22:32:51.577+0000] {processor.py:154} INFO - Started process (PID=25104) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:32:51.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:32:51.583+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:32:51.583+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:32:52.051+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:32:52.081+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:32:52.081+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:32:52.101+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:32:52.101+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:32:52.117+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.546 seconds
[2022-11-21T22:33:22.846+0000] {processor.py:154} INFO - Started process (PID=25138) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:33:22.849+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:33:22.851+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:33:22.851+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:33:23.173+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:33:23.204+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:33:23.203+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:33:23.224+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:33:23.224+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:33:23.240+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.400 seconds
[2022-11-21T22:33:53.862+0000] {processor.py:154} INFO - Started process (PID=25173) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:33:53.867+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:33:53.890+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:33:53.890+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:33:54.489+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:33:54.552+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:33:54.552+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:33:54.607+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:33:54.607+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:33:54.653+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.798 seconds
[2022-11-21T22:34:25.313+0000] {processor.py:154} INFO - Started process (PID=25207) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:34:25.321+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:34:25.324+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:34:25.324+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:34:25.616+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:34:25.643+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:34:25.643+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:34:25.662+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:34:25.662+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:34:25.676+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.369 seconds
[2022-11-21T22:34:56.291+0000] {processor.py:154} INFO - Started process (PID=25241) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:34:56.294+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:34:56.299+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:34:56.298+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:34:56.740+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:34:56.787+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:34:56.787+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:34:56.807+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:34:56.807+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:34:56.825+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.539 seconds
[2022-11-21T22:35:27.506+0000] {processor.py:154} INFO - Started process (PID=25266) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:35:27.508+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:35:27.510+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:35:27.509+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:35:27.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:35:27.926+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:35:27.925+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:35:27.965+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:35:27.964+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:35:28.008+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.506 seconds
[2022-11-21T22:35:58.432+0000] {processor.py:154} INFO - Started process (PID=25300) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:35:58.438+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:35:58.441+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:35:58.441+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:35:58.747+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:35:58.783+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:35:58.783+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:35:58.805+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:35:58.805+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:35:58.829+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.405 seconds
[2022-11-21T22:36:29.486+0000] {processor.py:154} INFO - Started process (PID=25334) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:36:29.490+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:36:29.494+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:36:29.494+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:36:29.976+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:36:30.008+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:36:30.008+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:36:30.031+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:36:30.031+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:36:30.049+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.570 seconds
[2022-11-21T22:37:00.625+0000] {processor.py:154} INFO - Started process (PID=25367) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:37:00.640+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:37:00.643+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:37:00.643+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:37:01.093+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:37:01.129+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:37:01.129+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:37:01.154+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:37:01.154+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:37:01.172+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.551 seconds
[2022-11-21T22:37:31.696+0000] {processor.py:154} INFO - Started process (PID=25401) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:37:31.699+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:37:31.702+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:37:31.702+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:37:32.075+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:37:32.108+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:37:32.107+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:37:32.132+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:37:32.132+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:37:32.148+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.457 seconds
[2022-11-21T22:38:02.703+0000] {processor.py:154} INFO - Started process (PID=25426) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:38:02.722+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:38:02.727+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:38:02.726+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:38:03.314+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:38:03.374+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:38:03.374+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:38:03.402+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:38:03.401+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:38:03.438+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.743 seconds
[2022-11-21T22:38:34.062+0000] {processor.py:154} INFO - Started process (PID=25460) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:38:34.067+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:38:34.069+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:38:34.069+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:38:34.631+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:38:34.672+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:38:34.672+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:38:34.695+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:38:34.695+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:38:34.713+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.658 seconds
[2022-11-21T22:39:05.245+0000] {processor.py:154} INFO - Started process (PID=25494) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:39:05.249+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:39:05.251+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:39:05.251+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:39:05.662+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:39:05.694+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:39:05.694+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:39:05.717+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:39:05.717+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:39:05.739+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.499 seconds
[2022-11-21T22:39:36.333+0000] {processor.py:154} INFO - Started process (PID=25527) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:39:36.335+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:39:36.337+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:39:36.337+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:39:36.791+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:39:36.832+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:39:36.832+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:39:36.852+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:39:36.852+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:39:36.869+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.542 seconds
[2022-11-21T22:40:07.460+0000] {processor.py:154} INFO - Started process (PID=25561) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:40:07.473+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:40:07.478+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:40:07.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:40:07.987+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:40:08.022+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:40:08.021+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:40:08.044+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:40:08.044+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:40:08.066+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.611 seconds
[2022-11-21T22:40:38.713+0000] {processor.py:154} INFO - Started process (PID=25585) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:40:38.716+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:40:38.717+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:40:38.717+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:40:39.538+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:40:39.583+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:40:39.583+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:40:39.607+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:40:39.606+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:40:39.643+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.934 seconds
[2022-11-21T22:41:10.357+0000] {processor.py:154} INFO - Started process (PID=25617) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:41:10.361+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:41:10.363+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:41:10.363+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:41:10.857+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:41:10.892+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:41:10.891+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:41:10.912+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:41:10.912+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:41:10.929+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.579 seconds
[2022-11-21T22:41:41.507+0000] {processor.py:154} INFO - Started process (PID=25651) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:41:41.526+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:41:41.528+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:41:41.528+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:41:42.030+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:41:42.068+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:41:42.067+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:41:42.092+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:41:42.092+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:41:42.111+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.611 seconds
[2022-11-21T22:42:12.798+0000] {processor.py:154} INFO - Started process (PID=25684) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:42:12.815+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:42:12.818+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:42:12.818+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:42:13.247+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:42:13.281+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:42:13.280+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:42:13.302+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:42:13.302+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:42:13.318+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.526 seconds
[2022-11-21T22:42:43.846+0000] {processor.py:154} INFO - Started process (PID=25719) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:42:43.850+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:42:43.854+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:42:43.854+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:42:44.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:42:44.406+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:42:44.405+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:42:44.436+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:42:44.436+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:42:44.453+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.615 seconds
[2022-11-21T22:43:15.250+0000] {processor.py:154} INFO - Started process (PID=25744) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:43:15.253+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:43:15.255+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:43:15.255+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:43:16.053+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:43:16.101+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:43:16.101+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:43:16.133+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:43:16.133+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:43:16.160+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.916 seconds
[2022-11-21T22:43:46.933+0000] {processor.py:154} INFO - Started process (PID=25778) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:43:46.936+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:43:46.938+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:43:46.938+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:43:47.342+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:43:47.378+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:43:47.378+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:43:47.400+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:43:47.400+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:43:47.415+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.486 seconds
[2022-11-21T22:44:17.989+0000] {processor.py:154} INFO - Started process (PID=25811) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:44:17.995+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:44:17.997+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:44:17.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:44:18.036+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:44:18.034+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 42
    return with open('resultsfile', 'w') as f:
              ^
SyntaxError: invalid syntax
[2022-11-21T22:44:18.041+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:44:18.078+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.096 seconds
[2022-11-21T22:44:48.212+0000] {processor.py:154} INFO - Started process (PID=25842) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:44:48.219+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:44:48.220+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:44:48.220+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:44:48.253+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:44:48.249+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 42
    return with open('resultsfile', 'w') as f:
              ^
SyntaxError: invalid syntax
[2022-11-21T22:44:48.256+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:44:48.293+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.085 seconds
[2022-11-21T22:45:19.248+0000] {processor.py:154} INFO - Started process (PID=25866) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:45:19.250+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:45:19.252+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:45:19.252+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:45:19.686+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:45:19.733+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:45:19.732+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:45:19.748+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:45:19.748+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:45:19.762+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.517 seconds
[2022-11-21T22:45:50.647+0000] {processor.py:154} INFO - Started process (PID=25900) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:45:50.649+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:45:50.651+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:45:50.651+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:45:51.082+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:45:51.116+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:45:51.115+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:45:51.138+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:45:51.138+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:45:51.155+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.514 seconds
[2022-11-21T22:46:21.803+0000] {processor.py:154} INFO - Started process (PID=25934) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:46:21.806+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:46:21.808+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:46:21.807+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:46:22.370+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:46:22.404+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:46:22.404+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:46:22.428+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:46:22.427+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:46:22.444+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.646 seconds
[2022-11-21T22:46:52.981+0000] {processor.py:154} INFO - Started process (PID=25968) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:46:52.986+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:46:52.990+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:46:52.990+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:46:53.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:46:53.580+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:46:53.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:46:53.604+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:46:53.603+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:46:53.619+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.647 seconds
[2022-11-21T22:47:24.186+0000] {processor.py:154} INFO - Started process (PID=26001) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:47:24.189+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:47:24.192+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:47:24.192+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:47:24.705+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:47:24.741+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:47:24.740+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:47:24.762+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:47:24.762+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:47:24.780+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.600 seconds
[2022-11-21T22:47:55.317+0000] {processor.py:154} INFO - Started process (PID=26026) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:47:55.320+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:47:55.322+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:47:55.321+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:47:55.712+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:47:55.745+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:47:55.745+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:47:55.766+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:47:55.766+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:47:55.781+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.468 seconds
[2022-11-21T22:48:26.383+0000] {processor.py:154} INFO - Started process (PID=26060) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:48:26.387+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:48:26.392+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:48:26.391+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:48:26.823+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:48:26.857+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:48:26.857+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:48:26.879+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:48:26.879+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:48:26.896+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.518 seconds
[2022-11-21T22:48:57.522+0000] {processor.py:154} INFO - Started process (PID=26094) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:48:57.526+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:48:57.531+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:48:57.530+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:48:58.002+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:48:58.043+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:48:58.043+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:48:58.064+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:48:58.064+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:48:58.083+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.568 seconds
[2022-11-21T22:49:28.637+0000] {processor.py:154} INFO - Started process (PID=26129) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:49:28.641+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:49:28.642+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:49:28.642+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:49:29.114+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:49:29.150+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:49:29.150+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:49:29.174+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:49:29.174+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:49:29.192+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.558 seconds
[2022-11-21T22:49:59.759+0000] {processor.py:154} INFO - Started process (PID=26154) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:49:59.762+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:49:59.765+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:49:59.764+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:50:00.289+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:50:00.343+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:50:00.342+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:50:00.382+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:50:00.382+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:50:00.428+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.676 seconds
[2022-11-21T22:50:31.293+0000] {processor.py:154} INFO - Started process (PID=26188) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:50:31.298+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:50:31.300+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:50:31.300+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:50:31.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:50:31.737+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:50:31.737+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:50:31.758+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:50:31.758+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:50:31.773+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.486 seconds
[2022-11-21T22:51:02.352+0000] {processor.py:154} INFO - Started process (PID=26221) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:51:02.375+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:51:02.377+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:51:02.377+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:51:02.831+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:51:02.869+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:51:02.869+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:51:02.890+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:51:02.889+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:51:02.907+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.561 seconds
[2022-11-21T22:51:33.534+0000] {processor.py:154} INFO - Started process (PID=26257) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:51:33.537+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:51:33.539+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:51:33.539+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:51:34.044+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:51:34.081+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:51:34.080+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:51:34.104+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:51:34.104+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:51:34.123+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.597 seconds
[2022-11-21T22:52:04.840+0000] {processor.py:154} INFO - Started process (PID=26290) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:52:04.848+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:52:04.855+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:52:04.855+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:52:05.702+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:52:05.803+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:52:05.803+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:52:05.848+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:52:05.848+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:52:05.885+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 1.053 seconds
[2022-11-21T22:52:36.734+0000] {processor.py:154} INFO - Started process (PID=26314) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:52:36.737+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:52:36.740+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:52:36.740+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:52:37.372+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:52:37.411+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:52:37.411+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:52:37.434+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:52:37.434+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:52:37.468+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.740 seconds
[2022-11-21T22:53:08.042+0000] {processor.py:154} INFO - Started process (PID=26348) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:53:08.045+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:53:08.047+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:53:08.047+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:53:08.432+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:53:08.469+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:53:08.468+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:53:08.490+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:53:08.490+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:53:08.507+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.468 seconds
[2022-11-21T22:53:39.037+0000] {processor.py:154} INFO - Started process (PID=26383) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:53:39.039+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:53:39.041+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:53:39.041+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:53:39.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:53:39.559+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:53:39.559+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:53:39.582+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:53:39.582+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:53:39.600+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.568 seconds
[2022-11-21T22:54:10.275+0000] {processor.py:154} INFO - Started process (PID=26417) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:54:10.278+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:54:10.285+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:54:10.285+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:54:10.747+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:54:10.796+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:54:10.796+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:54:10.827+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:54:10.827+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:54:10.859+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.598 seconds
[2022-11-21T22:54:41.453+0000] {processor.py:154} INFO - Started process (PID=26442) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:54:41.456+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:54:41.478+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:54:41.478+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:54:41.942+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:54:41.980+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:54:41.980+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:54:42.021+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:54:42.021+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:54:42.037+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.593 seconds
[2022-11-21T22:55:12.814+0000] {processor.py:154} INFO - Started process (PID=26475) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:12.817+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:55:12.820+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:12.820+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:13.376+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:13.423+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:13.423+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:55:13.451+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:13.451+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:55:13.474+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.666 seconds
[2022-11-21T22:55:16.949+0000] {processor.py:154} INFO - Started process (PID=26490) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:16.961+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:55:16.964+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:16.964+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:17.507+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:17.581+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:17.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:55:17.614+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:17.614+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:55:17.657+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.714 seconds
[2022-11-21T22:55:47.822+0000] {processor.py:154} INFO - Started process (PID=26516) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:47.826+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:55:47.835+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:47.835+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:48.102+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:55:48.126+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:48.126+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:55:48.142+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:55:48.142+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:55:48.152+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.335 seconds
[2022-11-21T22:56:18.398+0000] {processor.py:154} INFO - Started process (PID=26549) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:56:18.403+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:56:18.405+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:56:18.405+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:56:18.737+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:56:18.767+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:56:18.766+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:56:18.786+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:56:18.786+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:56:18.799+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.406 seconds
[2022-11-21T22:56:49.170+0000] {processor.py:154} INFO - Started process (PID=26584) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:56:49.173+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:56:49.175+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:56:49.175+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:56:49.449+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:56:49.478+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:56:49.478+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:56:49.493+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:56:49.493+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:56:49.503+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.338 seconds
[2022-11-21T22:57:20.032+0000] {processor.py:154} INFO - Started process (PID=26618) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:57:20.038+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:57:20.040+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:57:20.039+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:57:20.368+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:57:20.393+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:57:20.393+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:57:20.407+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:57:20.407+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:57:20.418+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.389 seconds
[2022-11-21T22:57:50.761+0000] {processor.py:154} INFO - Started process (PID=26642) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:57:50.764+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:57:50.766+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:57:50.766+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:57:51.025+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:57:51.052+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:57:51.052+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:57:51.069+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:57:51.069+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:57:51.081+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.324 seconds
[2022-11-21T22:58:21.230+0000] {processor.py:154} INFO - Started process (PID=26677) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:58:21.234+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:58:21.236+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:58:21.236+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:58:21.629+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:58:21.659+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:58:21.658+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:58:21.675+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:58:21.675+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:58:21.687+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.464 seconds
[2022-11-21T22:58:52.263+0000] {processor.py:154} INFO - Started process (PID=26711) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:58:52.267+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:58:52.269+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:58:52.269+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:58:52.540+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:58:52.566+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:58:52.565+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:58:52.580+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:58:52.580+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:58:52.591+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.332 seconds
[2022-11-21T22:59:22.835+0000] {processor.py:154} INFO - Started process (PID=26745) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:59:22.838+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:59:22.840+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:59:22.840+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:59:23.144+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:59:23.173+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:59:23.173+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:59:23.189+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:59:23.189+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:59:23.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.371 seconds
[2022-11-21T22:59:53.392+0000] {processor.py:154} INFO - Started process (PID=26771) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:59:53.395+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T22:59:53.397+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:59:53.397+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:59:53.650+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T22:59:53.676+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:59:53.676+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T22:59:53.691+0000] {logging_mixin.py:120} INFO - [2022-11-21T22:59:53.691+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T22:59:53.701+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.312 seconds
[2022-11-21T23:00:24.049+0000] {processor.py:154} INFO - Started process (PID=26804) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:00:24.052+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:00:24.053+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:00:24.053+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:00:24.372+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:00:24.399+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:00:24.399+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:00:24.416+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:00:24.415+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:00:24.426+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.380 seconds
[2022-11-21T23:00:54.776+0000] {processor.py:154} INFO - Started process (PID=26837) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:00:54.780+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:00:54.782+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:00:54.782+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:00:55.200+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:00:55.235+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:00:55.234+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:00:55.255+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:00:55.255+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:00:55.267+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.496 seconds
[2022-11-21T23:01:26.056+0000] {processor.py:154} INFO - Started process (PID=26869) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:01:26.059+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:01:26.060+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:01:26.060+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:01:26.462+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:01:26.497+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:01:26.497+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:01:26.518+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:01:26.517+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:01:26.534+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.482 seconds
[2022-11-21T23:01:57.300+0000] {processor.py:154} INFO - Started process (PID=26902) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:01:57.303+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:01:57.305+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:01:57.305+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:01:57.696+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:01:57.729+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:01:57.729+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:01:57.751+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:01:57.750+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:01:57.762+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.465 seconds
[2022-11-21T23:02:28.542+0000] {processor.py:154} INFO - Started process (PID=26927) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:02:28.546+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:02:28.549+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:02:28.549+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:02:29.156+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:02:29.201+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:02:29.200+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:02:29.228+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:02:29.228+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:02:29.265+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.728 seconds
[2022-11-21T23:02:59.999+0000] {processor.py:154} INFO - Started process (PID=26961) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:03:00.002+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:03:00.004+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:03:00.004+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:03:00.418+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:03:00.453+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:03:00.452+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:03:00.476+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:03:00.476+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:03:00.491+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.497 seconds
[2022-11-21T23:03:31.036+0000] {processor.py:154} INFO - Started process (PID=26994) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:03:31.038+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:03:31.040+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:03:31.040+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:03:31.552+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:03:31.593+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:03:31.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:03:31.612+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:03:31.612+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:03:31.625+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.595 seconds
[2022-11-21T23:04:02.267+0000] {processor.py:154} INFO - Started process (PID=27028) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:04:02.272+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:04:02.275+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:04:02.275+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:04:02.809+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:04:02.872+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:04:02.872+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:04:02.907+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:04:02.906+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:04:02.932+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.670 seconds
[2022-11-21T23:04:33.695+0000] {processor.py:154} INFO - Started process (PID=27061) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:04:33.701+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:04:33.703+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:04:33.703+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:04:34.588+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:04:34.626+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:04:34.626+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:04:34.648+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:04:34.647+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:04:34.674+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.986 seconds
[2022-11-21T23:05:05.351+0000] {processor.py:154} INFO - Started process (PID=27086) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:05:05.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:05:05.355+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:05:05.355+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:05:05.802+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:05:05.855+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:05:05.854+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:05:05.878+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:05:05.878+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:05:05.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.547 seconds
[2022-11-21T23:05:36.633+0000] {processor.py:154} INFO - Started process (PID=27120) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:05:36.637+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:05:36.639+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:05:36.639+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:05:37.251+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:05:37.293+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:05:37.293+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:05:37.318+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:05:37.318+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:05:37.337+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.711 seconds
[2022-11-21T23:06:07.939+0000] {processor.py:154} INFO - Started process (PID=27154) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:06:07.943+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:06:07.945+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:06:07.945+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:06:08.543+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:06:08.580+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:06:08.580+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:06:08.603+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:06:08.603+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:06:08.621+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.687 seconds
[2022-11-21T23:06:39.368+0000] {processor.py:154} INFO - Started process (PID=27186) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:06:39.373+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:06:39.375+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:06:39.375+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:06:39.793+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:06:39.840+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:06:39.840+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:06:39.867+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:06:39.867+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:06:39.891+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.529 seconds
[2022-11-21T23:07:10.460+0000] {processor.py:154} INFO - Started process (PID=27221) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:07:10.465+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:07:10.470+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:07:10.470+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:07:11.115+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:07:11.151+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:07:11.151+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:07:11.171+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:07:11.170+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:07:11.191+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.739 seconds
[2022-11-21T23:07:41.431+0000] {processor.py:154} INFO - Started process (PID=27246) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:07:41.434+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:07:41.436+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:07:41.436+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:07:41.873+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:07:41.910+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:07:41.909+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:07:41.930+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:07:41.930+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:07:41.949+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.527 seconds
[2022-11-21T23:08:12.620+0000] {processor.py:154} INFO - Started process (PID=27280) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:08:12.634+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:08:12.636+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:08:12.636+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:08:13.059+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:08:13.105+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:08:13.105+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:08:13.139+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:08:13.138+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:08:13.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.546 seconds
[2022-11-21T23:08:43.840+0000] {processor.py:154} INFO - Started process (PID=27315) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:08:43.844+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:08:43.848+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:08:43.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:08:44.303+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:08:44.341+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:08:44.341+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:08:44.363+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:08:44.363+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:08:44.381+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.546 seconds
[2022-11-21T23:09:15.110+0000] {processor.py:154} INFO - Started process (PID=27340) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:09:15.117+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:09:15.130+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:09:15.129+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:09:15.169+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:09:15.164+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 27
    self.s3().Bucket(self.bucket).upload_file(, self.bucket, self.postgres())
                                              ^
SyntaxError: invalid syntax
[2022-11-21T23:09:15.171+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:09:15.233+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.135 seconds
[2022-11-21T23:09:45.500+0000] {processor.py:154} INFO - Started process (PID=27373) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:09:45.503+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:09:45.505+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:09:45.505+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:09:46.088+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:09:46.137+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:09:46.136+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:09:46.154+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:09:46.154+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:09:46.167+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.671 seconds
[2022-11-21T23:10:17.003+0000] {processor.py:154} INFO - Started process (PID=27407) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:10:17.006+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:10:17.008+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:10:17.008+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:10:17.476+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:10:17.509+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:10:17.509+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:10:17.529+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:10:17.529+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:10:17.545+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.545 seconds
[2022-11-21T23:10:48.289+0000] {processor.py:154} INFO - Started process (PID=27441) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:10:48.292+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:10:48.294+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:10:48.294+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:10:48.706+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:10:48.739+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:10:48.739+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:10:48.759+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:10:48.759+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:10:48.778+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.493 seconds
[2022-11-21T23:11:19.480+0000] {processor.py:154} INFO - Started process (PID=27474) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:11:19.485+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:11:19.488+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:11:19.487+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:11:20.022+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:11:20.061+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:11:20.061+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:11:20.084+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:11:20.084+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:11:20.103+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.633 seconds
[2022-11-21T23:11:50.871+0000] {processor.py:154} INFO - Started process (PID=27499) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:11:50.874+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:11:50.876+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:11:50.876+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:11:51.252+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:11:51.285+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:11:51.285+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:11:51.306+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:11:51.306+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:11:51.321+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.454 seconds
[2022-11-21T23:12:21.972+0000] {processor.py:154} INFO - Started process (PID=27533) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:12:21.977+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:12:21.979+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:12:21.979+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:12:22.455+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:12:22.487+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:12:22.487+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:12:22.508+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:12:22.508+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:12:22.523+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.559 seconds
[2022-11-21T23:12:51.659+0000] {processor.py:154} INFO - Started process (PID=27566) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:12:51.663+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:12:51.666+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:12:51.666+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:12:52.394+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:12:52.445+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:12:52.445+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:12:52.480+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:12:52.480+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:12:52.509+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.862 seconds
[2022-11-21T23:13:22.611+0000] {processor.py:154} INFO - Started process (PID=27600) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:13:22.614+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:13:22.616+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:13:22.616+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:13:23.154+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:13:23.183+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:13:23.183+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:13:23.201+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:13:23.201+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:13:23.214+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.610 seconds
[2022-11-21T23:13:53.385+0000] {processor.py:154} INFO - Started process (PID=27625) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:13:53.391+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:13:53.397+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:13:53.396+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:13:53.966+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:13:54.011+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:13:54.011+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:13:54.047+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:13:54.047+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:13:54.064+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.685 seconds
[2022-11-21T23:14:24.956+0000] {processor.py:154} INFO - Started process (PID=27659) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:14:24.960+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:14:24.967+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:14:24.967+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:14:25.730+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:14:25.772+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:14:25.772+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:14:25.795+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:14:25.795+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:14:25.814+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.870 seconds
[2022-11-21T23:14:56.454+0000] {processor.py:154} INFO - Started process (PID=27693) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:14:56.457+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:14:56.459+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:14:56.459+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:14:56.864+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:14:56.895+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:14:56.894+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:14:56.915+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:14:56.915+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:14:56.933+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.484 seconds
[2022-11-21T23:15:27.687+0000] {processor.py:154} INFO - Started process (PID=27726) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:15:27.691+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:15:27.694+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:15:27.693+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:15:28.240+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:15:28.273+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:15:28.273+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:15:28.297+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:15:28.297+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:15:28.315+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.635 seconds
[2022-11-21T23:15:58.902+0000] {processor.py:154} INFO - Started process (PID=27760) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:15:58.904+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:15:58.906+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:15:58.906+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:15:59.427+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:15:59.462+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:15:59.462+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:15:59.485+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:15:59.485+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:15:59.503+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.605 seconds
[2022-11-21T23:16:30.042+0000] {processor.py:154} INFO - Started process (PID=27786) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:16:30.045+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:16:30.047+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:16:30.047+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:16:30.606+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:16:30.647+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:16:30.647+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:16:30.698+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:16:30.698+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:16:30.736+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.701 seconds
[2022-11-21T23:17:01.382+0000] {processor.py:154} INFO - Started process (PID=27819) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:17:01.385+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:17:01.387+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:17:01.387+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:17:01.805+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:17:01.837+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:17:01.837+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:17:01.857+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:17:01.857+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:17:01.876+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.500 seconds
[2022-11-21T23:17:32.613+0000] {processor.py:154} INFO - Started process (PID=27852) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:17:32.616+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:17:32.619+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:17:32.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:17:33.134+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:17:33.176+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:17:33.176+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:17:33.196+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:17:33.196+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:17:33.212+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.605 seconds
[2022-11-21T23:18:03.820+0000] {processor.py:154} INFO - Started process (PID=27886) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:18:03.824+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:18:03.831+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:18:03.831+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:18:04.361+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:18:04.399+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:18:04.399+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:18:04.423+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:18:04.423+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:18:04.447+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.635 seconds
[2022-11-21T23:18:35.116+0000] {processor.py:154} INFO - Started process (PID=27920) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:18:35.118+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:18:35.120+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:18:35.120+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:18:35.566+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:18:35.603+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:18:35.602+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:18:35.627+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:18:35.627+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:18:35.646+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.535 seconds
[2022-11-21T23:19:06.235+0000] {processor.py:154} INFO - Started process (PID=27944) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:19:06.240+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:19:06.243+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:19:06.242+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:19:06.787+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:19:06.829+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:19:06.828+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:19:06.860+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:19:06.860+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:19:06.880+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.663 seconds
[2022-11-21T23:19:37.602+0000] {processor.py:154} INFO - Started process (PID=27978) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:19:37.616+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:19:37.622+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:19:37.622+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:19:37.691+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:19:37.687+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 27
    self.s3()..Bucket(self.bucket)upload_file(self.postgres(), self.bucket, self.filename)
              ^
SyntaxError: invalid syntax
[2022-11-21T23:19:37.694+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:19:37.747+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.160 seconds
[2022-11-21T23:20:08.708+0000] {processor.py:154} INFO - Started process (PID=28009) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:20:08.712+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:20:08.714+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:20:08.714+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:20:08.751+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:20:08.747+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 27
    self.s3()..Bucket(self.bucket)upload_file(self.postgres(), self.bucket, self.filename)
              ^
SyntaxError: invalid syntax
[2022-11-21T23:20:08.752+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:20:08.778+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.077 seconds
[2022-11-21T23:20:39.765+0000] {processor.py:154} INFO - Started process (PID=28042) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:20:39.770+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:20:39.772+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:20:39.772+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:20:39.858+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:20:39.849+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 27
    self.s3()..Bucket(self.bucket)upload_file(self.postgres(), self.bucket, self.filename)
              ^
SyntaxError: invalid syntax
[2022-11-21T23:20:39.862+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:20:39.905+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.148 seconds
[2022-11-21T23:21:10.820+0000] {processor.py:154} INFO - Started process (PID=28075) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:21:10.827+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:21:10.833+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:21:10.833+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:21:10.907+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:21:10.900+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 27
    self.s3()..Bucket(self.bucket)upload_file(self.postgres(), self.bucket, self.filename)
              ^
SyntaxError: invalid syntax
[2022-11-21T23:21:10.914+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:21:10.997+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.182 seconds
[2022-11-21T23:21:42.056+0000] {processor.py:154} INFO - Started process (PID=28098) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:21:42.060+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:21:42.062+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:21:42.061+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:21:42.136+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:21:42.118+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 27
    self.s3()..Bucket(self.bucket)upload_file(self.postgres(), self.bucket, self.filename)
              ^
SyntaxError: invalid syntax
[2022-11-21T23:21:42.139+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:21:42.200+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.149 seconds
[2022-11-21T23:22:12.351+0000] {processor.py:154} INFO - Started process (PID=28131) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:22:12.354+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:22:12.356+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:22:12.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:22:12.415+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:22:12.412+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 27
    self.s3().Bucket(self.bucket)upload_file(self.postgres(), self.bucket, self.filename)
                                           ^
SyntaxError: invalid syntax
[2022-11-21T23:22:12.418+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:22:12.442+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.096 seconds
[2022-11-21T23:22:43.388+0000] {processor.py:154} INFO - Started process (PID=28165) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:22:43.393+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:22:43.399+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:22:43.399+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:22:43.844+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:22:43.891+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:22:43.891+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:22:43.909+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:22:43.908+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:22:43.928+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.548 seconds
[2022-11-21T23:23:14.055+0000] {processor.py:154} INFO - Started process (PID=28190) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:23:14.058+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:23:14.059+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:23:14.059+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:23:14.641+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:23:14.699+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:23:14.699+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:23:14.725+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:23:14.725+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:23:14.742+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.692 seconds
[2022-11-21T23:23:45.428+0000] {processor.py:154} INFO - Started process (PID=28224) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:23:45.435+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:23:45.439+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:23:45.439+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:23:45.872+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:23:45.900+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:23:45.900+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:23:45.920+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:23:45.920+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:23:45.946+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.521 seconds
[2022-11-21T23:24:16.320+0000] {processor.py:154} INFO - Started process (PID=28258) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:24:16.326+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:24:16.330+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:24:16.329+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:24:17.124+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:24:17.157+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:24:17.157+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:24:17.177+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:24:17.177+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:24:17.193+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.880 seconds
[2022-11-21T23:24:47.877+0000] {processor.py:154} INFO - Started process (PID=28294) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:24:47.880+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:24:47.882+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:24:47.882+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:24:48.304+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:24:48.333+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:24:48.333+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:24:48.347+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:24:48.347+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:24:48.358+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.490 seconds
[2022-11-21T23:25:18.937+0000] {processor.py:154} INFO - Started process (PID=28328) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:25:18.940+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:25:18.942+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:25:18.942+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:25:19.363+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:25:19.392+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:25:19.391+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:25:19.405+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:25:19.405+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:25:19.415+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.482 seconds
[2022-11-21T23:25:49.978+0000] {processor.py:154} INFO - Started process (PID=28353) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:25:49.982+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:25:49.985+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:25:49.984+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:25:50.452+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:25:50.478+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:25:50.477+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:25:50.496+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:25:50.496+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:25:50.508+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.536 seconds
[2022-11-21T23:26:20.728+0000] {processor.py:154} INFO - Started process (PID=28386) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:26:20.734+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:26:20.738+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:26:20.738+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:26:21.115+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:26:21.140+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:26:21.140+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:26:21.155+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:26:21.155+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:26:21.166+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.448 seconds
[2022-11-21T23:26:51.544+0000] {processor.py:154} INFO - Started process (PID=28420) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:26:51.547+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:26:51.549+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:26:51.548+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:26:51.989+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:26:52.015+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:26:52.015+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:26:52.030+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:26:52.030+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:26:52.043+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.504 seconds
[2022-11-21T23:27:22.633+0000] {processor.py:154} INFO - Started process (PID=28454) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:27:22.636+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:27:22.638+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:27:22.638+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:27:23.077+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:27:23.104+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:27:23.104+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:27:23.119+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:27:23.119+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:27:23.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.502 seconds
[2022-11-21T23:27:53.243+0000] {processor.py:154} INFO - Started process (PID=28481) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:27:53.245+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:27:53.247+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:27:53.247+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:27:53.650+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:27:53.679+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:27:53.679+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:27:53.702+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:27:53.702+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:27:53.727+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.487 seconds
[2022-11-21T23:28:24.528+0000] {processor.py:154} INFO - Started process (PID=28515) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:28:24.531+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:28:24.533+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:28:24.533+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:28:24.959+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:28:24.989+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:28:24.989+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:28:25.004+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:28:25.004+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:28:25.014+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.491 seconds
[2022-11-21T23:28:56.060+0000] {processor.py:154} INFO - Started process (PID=28548) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:28:56.063+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:28:56.065+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:28:56.065+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:28:56.469+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:28:56.502+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:28:56.501+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:28:56.518+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:28:56.518+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:28:56.530+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.473 seconds
[2022-11-21T23:29:26.620+0000] {processor.py:154} INFO - Started process (PID=28581) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:29:26.623+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:29:26.625+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:29:26.625+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:29:26.893+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:29:26.918+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:29:26.918+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:29:26.935+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:29:26.935+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:29:26.945+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.331 seconds
[2022-11-21T23:29:57.173+0000] {processor.py:154} INFO - Started process (PID=28613) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:29:57.175+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:29:57.177+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:29:57.177+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:29:57.581+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:29:57.611+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:29:57.611+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:29:57.637+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:29:57.637+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:29:57.652+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.483 seconds
[2022-11-21T23:30:27.918+0000] {processor.py:154} INFO - Started process (PID=28637) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:30:27.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:30:27.928+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:30:27.928+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:30:28.200+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:30:28.227+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:30:28.226+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:30:28.252+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:30:28.252+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:30:28.279+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.366 seconds
[2022-11-21T23:30:59.316+0000] {processor.py:154} INFO - Started process (PID=28670) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:30:59.327+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:30:59.332+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:30:59.332+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:31:00.630+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:31:00.678+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:31:00.677+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:31:00.712+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:31:00.712+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:31:00.731+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 1.438 seconds
[2022-11-21T23:31:31.489+0000] {processor.py:154} INFO - Started process (PID=28704) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:31:31.492+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:31:31.494+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:31:31.493+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:31:32.015+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:31:32.087+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:31:32.086+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:31:32.141+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:31:32.139+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:31:32.179+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.700 seconds
[2022-11-21T23:32:02.922+0000] {processor.py:154} INFO - Started process (PID=28738) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:32:02.947+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:32:02.950+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:32:02.949+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:32:03.611+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:32:03.651+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:32:03.650+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:32:03.669+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:32:03.669+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:32:03.687+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.776 seconds
[2022-11-21T23:32:34.346+0000] {processor.py:154} INFO - Started process (PID=28771) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:32:34.363+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:32:34.365+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:32:34.365+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:32:34.943+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:32:34.979+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:32:34.979+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:32:35.001+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:32:35.001+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:32:35.019+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.683 seconds
[2022-11-21T23:33:05.663+0000] {processor.py:154} INFO - Started process (PID=28805) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:33:05.667+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:33:05.674+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:33:05.674+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:33:06.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:33:06.035+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:33:06.035+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:33:06.056+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:33:06.056+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:33:06.071+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.412 seconds
[2022-11-21T23:33:36.709+0000] {processor.py:154} INFO - Started process (PID=28831) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:33:36.715+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:33:36.718+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:33:36.718+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:33:37.457+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:33:37.525+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:33:37.524+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:33:37.566+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:33:37.565+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:33:37.608+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.907 seconds
[2022-11-21T23:34:08.395+0000] {processor.py:154} INFO - Started process (PID=28864) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:34:08.400+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:34:08.407+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:34:08.406+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:34:08.877+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:34:08.910+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:34:08.910+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:34:08.939+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:34:08.938+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:34:08.955+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.568 seconds
[2022-11-21T23:34:39.489+0000] {processor.py:154} INFO - Started process (PID=28897) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:34:39.495+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:34:39.497+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:34:39.497+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:34:39.905+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:34:39.939+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:34:39.938+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:34:39.959+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:34:39.959+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:34:39.974+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.488 seconds
[2022-11-21T23:35:10.663+0000] {processor.py:154} INFO - Started process (PID=28931) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:35:10.668+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:35:10.693+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:35:10.693+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:35:11.113+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:35:11.146+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:35:11.146+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:35:11.166+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:35:11.166+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:35:11.182+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.528 seconds
[2022-11-21T23:35:41.858+0000] {processor.py:154} INFO - Started process (PID=28966) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:35:41.866+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:35:41.869+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:35:41.869+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:35:42.332+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:35:42.368+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:35:42.368+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:35:42.392+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:35:42.392+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:35:42.407+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.554 seconds
[2022-11-21T23:36:13.063+0000] {processor.py:154} INFO - Started process (PID=28998) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:36:13.068+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:36:13.071+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:36:13.071+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:36:13.542+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:36:13.594+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:36:13.593+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:36:13.625+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:36:13.624+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:36:13.645+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.586 seconds
[2022-11-21T23:36:44.347+0000] {processor.py:154} INFO - Started process (PID=29025) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:36:44.351+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:36:44.353+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:36:44.353+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:36:44.822+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:36:44.859+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:36:44.859+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:36:44.881+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:36:44.881+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:36:44.898+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.560 seconds
[2022-11-21T23:37:15.491+0000] {processor.py:154} INFO - Started process (PID=29059) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:37:15.495+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:37:15.498+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:37:15.497+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:37:15.998+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:37:16.055+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:37:16.054+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:37:16.098+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:37:16.098+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:37:16.151+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.666 seconds
[2022-11-21T23:37:46.658+0000] {processor.py:154} INFO - Started process (PID=29093) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:37:46.662+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:37:46.665+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:37:46.664+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:37:47.158+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:37:47.192+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:37:47.191+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:37:47.212+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:37:47.212+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:37:47.226+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.574 seconds
[2022-11-21T23:38:17.893+0000] {processor.py:154} INFO - Started process (PID=29127) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:38:17.897+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:38:17.899+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:38:17.899+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:38:18.381+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:38:18.414+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:38:18.414+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:38:18.436+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:38:18.436+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:38:18.454+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.565 seconds
[2022-11-21T23:38:49.056+0000] {processor.py:154} INFO - Started process (PID=29152) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:38:49.059+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:38:49.061+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:38:49.061+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:38:49.516+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:38:49.547+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:38:49.547+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:38:49.569+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:38:49.569+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:38:49.586+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.534 seconds
[2022-11-21T23:39:20.161+0000] {processor.py:154} INFO - Started process (PID=29187) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:39:20.165+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:39:20.168+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:39:20.168+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:39:21.038+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:39:21.077+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:39:21.077+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:39:21.101+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:39:21.101+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:39:21.125+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.969 seconds
[2022-11-21T23:39:51.775+0000] {processor.py:154} INFO - Started process (PID=29221) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:39:51.779+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:39:51.781+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:39:51.781+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:39:52.210+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:39:52.243+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:39:52.243+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:39:52.260+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:39:52.260+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:39:52.285+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.516 seconds
[2022-11-21T23:40:23.009+0000] {processor.py:154} INFO - Started process (PID=29255) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:40:23.012+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:40:23.014+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:40:23.014+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:40:23.442+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:40:23.474+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:40:23.474+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:40:23.494+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:40:23.494+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:40:23.509+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.507 seconds
[2022-11-21T23:40:54.190+0000] {processor.py:154} INFO - Started process (PID=29289) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:40:54.193+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:40:54.195+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:40:54.195+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:40:54.960+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:40:55.043+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:40:55.042+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:40:55.104+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:40:55.104+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:40:55.133+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.948 seconds
[2022-11-21T23:41:25.805+0000] {processor.py:154} INFO - Started process (PID=29314) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:41:25.808+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:41:25.810+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:41:25.810+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:41:26.719+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:41:26.769+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:41:26.768+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:41:26.810+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:41:26.810+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:41:26.835+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 1.034 seconds
[2022-11-21T23:41:57.451+0000] {processor.py:154} INFO - Started process (PID=29348) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:41:57.457+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:41:57.461+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:41:57.460+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:41:58.017+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:41:58.058+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:41:58.058+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:41:58.080+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:41:58.080+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:41:58.108+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.675 seconds
[2022-11-21T23:42:29.018+0000] {processor.py:154} INFO - Started process (PID=29381) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:42:29.023+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:42:29.029+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:42:29.028+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:42:29.589+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:42:29.627+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:42:29.627+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:42:29.658+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:42:29.658+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:42:29.679+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.668 seconds
[2022-11-21T23:43:00.403+0000] {processor.py:154} INFO - Started process (PID=29415) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:43:00.406+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:43:00.408+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:43:00.408+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:43:00.850+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:43:00.897+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:43:00.897+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:43:00.920+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:43:00.920+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:43:00.935+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.537 seconds
[2022-11-21T23:43:31.626+0000] {processor.py:154} INFO - Started process (PID=29449) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:43:31.629+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:43:31.631+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:43:31.631+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:43:32.133+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:43:32.165+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:43:32.165+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:43:32.185+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:43:32.185+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:43:32.202+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.580 seconds
[2022-11-21T23:44:03.197+0000] {processor.py:154} INFO - Started process (PID=29480) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:44:03.205+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:44:03.218+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:44:03.217+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:44:04.007+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:44:04.065+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:44:04.064+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:44:04.132+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:44:04.131+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:44:04.183+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.992 seconds
[2022-11-21T23:44:34.879+0000] {processor.py:154} INFO - Started process (PID=29507) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:44:34.883+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:44:34.886+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:44:34.885+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:44:35.395+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:44:35.432+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:44:35.432+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:44:35.453+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:44:35.453+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:44:35.477+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.603 seconds
[2022-11-21T23:45:06.117+0000] {processor.py:154} INFO - Started process (PID=29541) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:45:06.121+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:45:06.124+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:45:06.124+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:45:06.596+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:45:06.632+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:45:06.631+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:45:06.652+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:45:06.652+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:45:06.675+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.564 seconds
[2022-11-21T23:45:37.614+0000] {processor.py:154} INFO - Started process (PID=29576) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:45:37.617+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:45:37.619+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:45:37.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:45:38.096+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:45:38.134+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:45:38.134+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:45:38.156+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:45:38.156+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:45:38.173+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.565 seconds
[2022-11-21T23:46:08.894+0000] {processor.py:154} INFO - Started process (PID=29610) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:46:08.897+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:46:08.899+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:46:08.899+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:46:09.440+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:46:09.477+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:46:09.476+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:46:09.501+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:46:09.501+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:46:09.518+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.630 seconds
[2022-11-21T23:46:40.223+0000] {processor.py:154} INFO - Started process (PID=29635) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:46:40.228+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:46:40.231+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:46:40.231+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:46:41.334+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:46:41.522+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:46:41.522+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:46:41.556+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:46:41.556+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:46:41.613+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 1.400 seconds
[2022-11-21T23:47:12.249+0000] {processor.py:154} INFO - Started process (PID=29669) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:47:12.251+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:47:12.252+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:47:12.252+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:47:12.670+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:47:12.706+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:47:12.706+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:47:12.728+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:47:12.728+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:47:12.744+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.526 seconds
[2022-11-21T23:47:43.490+0000] {processor.py:154} INFO - Started process (PID=29703) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:47:43.495+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:47:43.498+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:47:43.498+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:47:43.958+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:47:43.996+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:47:43.996+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:47:44.017+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:47:44.017+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:47:44.033+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.553 seconds
[2022-11-21T23:48:14.678+0000] {processor.py:154} INFO - Started process (PID=29736) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:48:14.681+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:48:14.682+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:48:14.682+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:48:15.122+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:48:15.156+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:48:15.156+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:48:15.186+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:48:15.186+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:48:15.206+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.534 seconds
[2022-11-21T23:48:45.908+0000] {processor.py:154} INFO - Started process (PID=29769) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:48:45.911+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:48:45.913+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:48:45.913+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:48:46.396+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:48:46.436+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:48:46.436+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:48:46.458+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:48:46.457+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:48:46.474+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.573 seconds
[2022-11-21T23:49:17.073+0000] {processor.py:154} INFO - Started process (PID=29794) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:49:17.076+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:49:17.094+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:49:17.094+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:49:17.598+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:49:17.640+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:49:17.640+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:49:17.660+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:49:17.659+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:49:17.674+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.613 seconds
[2022-11-21T23:49:48.755+0000] {processor.py:154} INFO - Started process (PID=29828) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:49:48.758+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:49:48.760+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:49:48.760+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:49:49.200+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:49:49.237+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:49:49.236+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:49:49.261+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:49:49.260+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:49:49.278+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.532 seconds
[2022-11-21T23:50:19.923+0000] {processor.py:154} INFO - Started process (PID=29862) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:50:19.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:50:19.928+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:50:19.928+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:50:20.385+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:50:20.421+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:50:20.420+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:50:20.461+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:50:20.461+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:50:20.494+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.578 seconds
[2022-11-21T23:50:51.245+0000] {processor.py:154} INFO - Started process (PID=29896) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:50:51.248+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:50:51.250+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:50:51.249+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:50:51.701+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:50:51.736+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:50:51.735+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:50:51.757+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:50:51.756+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:50:51.774+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.535 seconds
[2022-11-21T23:51:22.414+0000] {processor.py:154} INFO - Started process (PID=29928) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:51:22.417+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:51:22.419+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:51:22.419+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:51:22.828+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:51:22.868+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:51:22.868+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:51:22.897+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:51:22.897+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:51:22.916+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.506 seconds
[2022-11-21T23:51:53.749+0000] {processor.py:154} INFO - Started process (PID=29952) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:51:53.753+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:51:53.758+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:51:53.758+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:51:54.299+0000] {processor.py:766} INFO - DAG(s) dict_keys(['PG_to_S3']) retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:51:54.342+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:51:54.342+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-11-21T23:51:54.368+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:51:54.368+0000] {dag.py:3340} INFO - Setting next_dagrun for PG_to_S3 to 2022-11-21T00:00:00+00:00, run_after=2022-11-22T00:00:00+00:00
[2022-11-21T23:51:54.395+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.653 seconds
[2022-11-21T23:52:25.179+0000] {processor.py:154} INFO - Started process (PID=29985) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:52:25.183+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:52:25.185+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:52:25.185+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:52:25.250+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:52:25.245+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("", filename), "wb") as file:
                                                      ^
SyntaxError: invalid syntax
[2022-11-21T23:52:25.254+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:52:25.291+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.121 seconds
[2022-11-21T23:52:55.338+0000] {processor.py:154} INFO - Started process (PID=30018) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:52:55.342+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:52:55.345+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:52:55.345+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:52:55.380+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:52:55.378+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:52:55.381+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:52:55.410+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.076 seconds
[2022-11-21T23:53:26.168+0000] {processor.py:154} INFO - Started process (PID=30051) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:53:26.171+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:53:26.177+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:53:26.177+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:53:26.206+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:53:26.203+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:53:26.207+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:53:26.225+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.061 seconds
[2022-11-21T23:53:56.983+0000] {processor.py:154} INFO - Started process (PID=30084) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:53:56.986+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:53:57.008+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:53:57.007+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:53:57.040+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:53:57.037+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:53:57.041+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:53:57.061+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.081 seconds
[2022-11-21T23:54:27.822+0000] {processor.py:154} INFO - Started process (PID=30108) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:54:27.826+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:54:27.828+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:54:27.827+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:54:27.857+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:54:27.851+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:54:27.858+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:54:27.876+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.058 seconds
[2022-11-21T23:54:58.773+0000] {processor.py:154} INFO - Started process (PID=30141) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:54:58.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:54:58.778+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:54:58.778+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:54:58.824+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:54:58.804+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:54:58.828+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:54:58.854+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.086 seconds
[2022-11-21T23:55:29.923+0000] {processor.py:154} INFO - Started process (PID=30175) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:55:29.926+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:55:29.928+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:55:29.928+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:55:29.972+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:55:29.970+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:55:29.973+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:55:29.994+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.076 seconds
[2022-11-21T23:56:00.767+0000] {processor.py:154} INFO - Started process (PID=30208) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:56:00.769+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:56:00.772+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:56:00.771+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:56:00.813+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:56:00.811+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:56:00.816+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:56:00.841+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.078 seconds
[2022-11-21T23:56:31.534+0000] {processor.py:154} INFO - Started process (PID=30242) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:56:31.537+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:56:31.541+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:56:31.541+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:56:31.579+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:56:31.575+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:56:31.586+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:56:31.613+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.082 seconds
[2022-11-21T23:57:02.378+0000] {processor.py:154} INFO - Started process (PID=30267) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:57:02.397+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:57:02.399+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:57:02.399+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:57:02.430+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:57:02.428+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:57:02.432+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:57:02.454+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.082 seconds
[2022-11-21T23:57:33.376+0000] {processor.py:154} INFO - Started process (PID=30300) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:57:33.378+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:57:33.380+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:57:33.380+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:57:33.409+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:57:33.405+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:57:33.411+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:57:33.437+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.067 seconds
[2022-11-21T23:58:04.215+0000] {processor.py:154} INFO - Started process (PID=30333) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:58:04.218+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:58:04.221+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:58:04.221+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:58:04.277+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:58:04.271+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:58:04.281+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:58:04.333+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.129 seconds
[2022-11-21T23:58:35.080+0000] {processor.py:154} INFO - Started process (PID=30366) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:58:35.087+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:58:35.091+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:58:35.090+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:58:35.171+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:58:35.160+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:58:35.176+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:58:35.224+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.152 seconds
[2022-11-21T23:59:05.321+0000] {processor.py:154} INFO - Started process (PID=30390) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:59:05.323+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:59:05.325+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:59:05.324+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:59:05.358+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:59:05.356+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:59:05.359+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:59:05.383+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.067 seconds
[2022-11-21T23:59:35.825+0000] {processor.py:154} INFO - Started process (PID=30423) to work on /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:59:35.842+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/PGtoS3.py for tasks to queue
[2022-11-21T23:59:35.848+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:59:35.848+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:59:35.905+0000] {logging_mixin.py:120} INFO - [2022-11-21T23:59:35.902+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/PGtoS3.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/PGtoS3.py", line 5, in <module>
    from operators.pgtos3 import PostgresToS3Operator
  File "/opt/airflow/plugins/operators/pgtos3.py", line 39
    open(os.path.join("/opt/airflow/data", filename), "wb") as file:
                                                             ^
SyntaxError: invalid syntax
[2022-11-21T23:59:35.907+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/PGtoS3.py
[2022-11-21T23:59:35.931+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/PGtoS3.py took 0.122 seconds
